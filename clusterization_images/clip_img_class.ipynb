{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификация изображений на основе векторизации c использованием CLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWcs_ltAGQJ8"
   },
   "source": [
    "## Зависимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_74MhPaGY9e"
   },
   "source": [
    "### Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nwEy0oGXF__g"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNqbgaL9hoiZ",
    "outputId": "426427a8-7924-4c17-e1e3-588278d0bae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kneed in /home/eu2233-6/.local/lib/python3.10/site-packages (0.8.3)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kneed) (1.7.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kneed[plot] in /home/eu2233-6/.local/lib/python3.10/site-packages (0.8.3)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from kneed[plot]) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kneed[plot]) (1.7.3)\n",
      "Requirement already satisfied: matplotlib>=2.2.5 in /usr/local/lib/python3.10/dist-packages (from kneed[plot]) (3.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (4.34.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.5->kneed[plot]) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.5->kneed[plot]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install kneed\n",
    "! pip install kneed[plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zz_C1dg2NBuZ",
    "outputId": "914d238c-bfd2-4806-da3d-e3cada686a76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ftfy in /home/eu2233-6/.local/lib/python3.10/site-packages (6.1.1)\n",
      "Requirement already satisfied: regex in /home/eu2233-6/.local/lib/python3.10/site-packages (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.64.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "evFVIoVlNOjo",
    "outputId": "d68ea8c1-513c-4706-a51a-458f50269b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-th49ttzt\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-th49ttzt\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a9b1bf5920416aaeaec965c25dd9e8f98c864f16\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /home/eu2233-6/.local/lib/python3.10/site-packages (from clip==1.0) (6.1.1)\n",
      "Requirement already satisfied: regex in /home/eu2233-6/.local/lib/python3.10/site-packages (from clip==1.0) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.64.0)\n",
      "Requirement already satisfied: torch in /home/eu2233-6/.local/lib/python3.10/site-packages (from clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /home/eu2233-6/.local/lib/python3.10/site-packages (from clip==1.0) (0.14.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/eu2233-6/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/eu2233-6/.local/lib/python3.10/site-packages (from torch->clip==1.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/eu2233-6/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/eu2233-6/.local/lib/python3.10/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (65.3.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.37.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.22.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (2.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (9.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->clip==1.0) (3.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/eu2233-6/.local/lib/python3.10/site-packages (4.29.0)\n",
      "Requirement already satisfied: datasets in /home/eu2233-6/.local/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/eu2233-6/.local/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/eu2233-6/.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from datasets) (12.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: xxhash in /home/eu2233-6/.local/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/eu2233-6/.local/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/eu2233-6/.local/lib/python3.10/site-packages (from datasets) (2023.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/eu2233-6/.local/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Yv2sqSm-kvt4",
    "outputId": "54ec8c0a-ef5d-4f34-bdd0-e5e9569f2bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/eu2233-6/.local/lib/python3.10/site-packages (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (23.5.8)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (1.54.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (0.4.9)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (4.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (65.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.7.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/eu2233-6/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/eu2233-6/.local/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "BbmGZA6pNIHa",
    "outputId": "05c3646d-36b7-43d9-db12-0d6bc71c7e92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pkg_resources import packaging\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "372sK1S8NLwI"
   },
   "outputs": [],
   "source": [
    "import clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TP0R986XNVUz"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgdown\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnatsort\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m natsorted, ns\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import cv2 as cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import gdown\n",
    "from natsort import natsorted, ns\n",
    "from pathlib import Path\n",
    "from random import sample, randint\n",
    "from PIL import Image, ImageOps\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2JxbyGeEpjBl"
   },
   "outputs": [],
   "source": [
    "# определяем колонку по которой будем связывать все таблицы\n",
    "global_key = 'regNumber'\n",
    "\n",
    "# путь к папке к изображениями из ГК\n",
    "img_data_url = './data/img_for_clasifire/V__270523/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ссылки \n",
    "url_dict = {\n",
    "    'clear_data_list':'./out/gk_out/clear_data_list.csv',    \n",
    "    'plot_list':'./out/gk_out/plot_list.csv',  \n",
    "    'sample_objects':'./out/gk_out/sample_objects.csv',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sZ7UKuPivZT"
   },
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "w-VGwRKOiDPm"
   },
   "outputs": [],
   "source": [
    "# для многоканальной обработки списка любой функцией\n",
    "def to_pool(item_list, method):\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "         rezult_list = []\n",
    "         for res in tqdm(pool.imap(method, (i for i in item_list)),\n",
    "                     total = len(item_list)):\n",
    "             rezult_list.append(res)\n",
    "    return rezult_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hjGKcTotvA3Q"
   },
   "outputs": [],
   "source": [
    "def to_tqdm(item_list, method):\n",
    "  rezult_list = []\n",
    "  for res in tqdm(map(method, (i for i in item_list)),\n",
    "                     total = len(item_list)):\n",
    "             rezult_list.append(res)\n",
    "  return rezult_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nluV6GfRhhQs"
   },
   "outputs": [],
   "source": [
    "# вывод изображений\n",
    "def show_img(image_list, name = True, col = 5, cv2_img = False, suptitle='', title_key = global_key):\n",
    "    row = len(image_list) // col + 1\n",
    "\n",
    "    plt.figure(figsize=(6.4, 2.4*row))\n",
    "    for i in range(0,len(image_list)):\n",
    "        plt.subplot(row, col, i + 1)\n",
    "        plt.suptitle(suptitle)\n",
    "        plt.axis('off')\n",
    "        if name:\n",
    "           title = str(image_list[i][title_key])\n",
    "        else:\n",
    "           title =  'N' + str(i+1)\n",
    "        plt.title(f\"{title}\")\n",
    "        if cv2_img:\n",
    "           plt.imshow(cv2.cvtColor(image_list[i]['img'], cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "           plt.imshow(image_list[i]['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CoFmYKNqSj9Z"
   },
   "outputs": [],
   "source": [
    "# считать список файлов из всех поддерикторий\n",
    "# возвращает список имен файлов и уникальные расширения файлов\n",
    "def get_file_list(path):\n",
    "    rezult = []\n",
    "    variant = set()\n",
    "    for root, dirs, files in os.walk(path, topdown = False):\n",
    "        for name in files:\n",
    "            rezult.append(os.path.join(root, name))\n",
    "            # если нет расширений у файлов добавляем None, иначе - название расширения\n",
    "            file_extension = name.split('.')[1] if len(name.split('.')) > 1 else None\n",
    "            variant.add(file_extension)\n",
    "    return rezult, variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQin4fMFl2x7"
   },
   "outputs": [],
   "source": [
    "# на вход передается путь к имени файла и список id объектов. id соответствует первой части имени файла\n",
    "# по маске id_*.jpg\n",
    "def filter_fille_name(fille_path, id_list):\n",
    "    fille_name = fille_path.split('/')[-1]\n",
    "    return fille_name.split('.')[0].split('_')[0] in id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3l9zS4GzjvUH"
   },
   "outputs": [],
   "source": [
    "# считать список файлов из всех поддерикторий\n",
    "# возвращает список имен файлов и уникальные расширения файлов\n",
    "def get_filter_file_list(path, name_list):\n",
    "    rezult = []\n",
    "    variant = set()\n",
    "    for root, dirs, files in os.walk(path, topdown = False):\n",
    "        for name in files:\n",
    "            if not(filter_fille_name(name, name_list)):\n",
    "               continue\n",
    "            rezult.append(os.path.join(root, name))\n",
    "            # если нет расширений у файлов добавляем None, иначе - название расширения\n",
    "            file_extension = name.split('.')[1] if len(name.split('.')) > 1 else None\n",
    "            variant.add(file_extension)\n",
    "    return rezult, variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un9ay3ZZWIn5"
   },
   "outputs": [],
   "source": [
    "# %load ./src/functions/save2csv.py\n",
    "\n",
    "# сохраняем в файл результаты\n",
    "def save2csv(df, param='data'):\n",
    "    file_name = './out/' + param + '_' + str(randint(100, 2000)) +'.csv'\n",
    "    df.to_csv(file_name, index= False )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv5CkApuGUqv"
   },
   "source": [
    "### Данные\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшей работы используются результаты выгрузки данных ГК.\n",
    "Файлы изображений должны именоваться по следующему шаблону:\n",
    "regNumber_postfics.jpg, где\n",
    "\n",
    "regNumber - регестрационный номер в ГК, это id служит для связи между изображением и предметом\n",
    "postfics - число 1, 2 или 3, где 1 - обозначает основное изображение в карточке объекта в ГК, 2, 3 - остальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmKC29qNo9zX"
   },
   "outputs": [],
   "source": [
    "# возвращает id объекта из пути к файлу картинки и преффикс 1 или 2\n",
    "\n",
    "# fille_path - путь к файлу\n",
    "def setImgId(fille_path):\n",
    "  fille_name = fille_path.split('/')[-1]\n",
    "  return fille_name.split('.')[0].split('_')[0], fille_name.split('.')[0].split('_')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCWSGeAfrJgJ"
   },
   "outputs": [],
   "source": [
    "# возвращает id объекта из пути к файлу картинки\n",
    "\n",
    "# fille_path - путь к файлу\n",
    "def getImgId(fille_path):\n",
    "  return int(setImgId(fille_path)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgKYANaUrddW"
   },
   "outputs": [],
   "source": [
    "# возвращает преффикс 1 или 2 объекта из пути к файлу картинки\n",
    "\n",
    "# fille_path - путь к файлу\n",
    "def filterImgPreff(fille_path, pref_list = [1, '1']):\n",
    "    fille_pref = setImgId(fille_path)[1]\n",
    "    return fille_pref in pref_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5BM0wq3vgax"
   },
   "outputs": [],
   "source": [
    "# возвращает метку кластера для переданного изображения\n",
    "\n",
    "# line - словарь вида {'img': изображение формата PIA/CV2, 'title':путь к файлу, 'regNumber':id по которому матчатся таблицы}\n",
    "# loc_key = '' - название столбца по которому соединяются таблицы (если не указан - 'regNumber')\n",
    "def setTrueLabel(line, loc_key = ''):\n",
    "  key = loc_key if loc_key else global_key\n",
    "  img_id = int(line[key])\n",
    "  return valid_table_df.loc[valid_table_df[key] == img_id]['label_true'].tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wcW_OS6jS2I"
   },
   "outputs": [],
   "source": [
    "# конвертация в формат cv2\n",
    "# возвращает словарь вида {'img':вектор изображения в формате CV2,'title':название}\n",
    "\n",
    "# filename - полный путь к файлу\n",
    "def file2cv2(filename):\n",
    "     return {'img':cv2.imread(filename), 'title':filename}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUJvx6O_stRs"
   },
   "outputs": [],
   "source": [
    "# конвертация в формат cv2\n",
    "# возвращает словарь вида {'img':вектор изображения в формате PIL,'title':название}\n",
    "\n",
    "# filename - полный путь к файлу\n",
    "def file2PIL(filename):\n",
    "     return {'img': Image.open(filename), 'title':filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl3vrXzCHj5Q"
   },
   "outputs": [],
   "source": [
    "# скачать с гугл-диска таблицу в формате csv\n",
    "# возвращает таблицу\n",
    "\n",
    "# url - ссылка доступа, полученная с гугл-диска\n",
    "def downloadFromDriverCSV(url, sep = ','):\n",
    "   file_id=url.split('/')[-2]\n",
    "   dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "   df = pd.read_csv(dwn_url, encoding = 'utf8', sep = sep)\n",
    "\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frQFcxDOdHSs"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX-KwaG0HuhZ"
   },
   "source": [
    "#### Изображения и список ралевантных изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDkHJZp9eHF3"
   },
   "outputs": [],
   "source": [
    "# создаем список id ролевантных изображений\n",
    "table_df = csv2DF('clear_data_list')\n",
    "clear_id_list = table_df[global_key].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcprUGl2Sn7v"
   },
   "outputs": [],
   "source": [
    "# загрузка изображений \n",
    "# img_list - список изображений\n",
    "# type_set - список расширений загруженных файлов для проверки результатов\n",
    "img_list, type_set = get_file_list(img_data_url)\n",
    "type_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6ATMm3EgVuV"
   },
   "source": [
    "Два варианта - либо создаем список картинок без класса 0 отфильтровав img_list если работаем с неочищенным списком. Либо сразу грузим только нужные картинки (пока закоментировала этот вариант)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBktj_Yki8fd"
   },
   "outputs": [],
   "source": [
    "#img_list_clear, type_set_clear = get_filter_file_list(google_foolder, clear_id_list)\n",
    "clear_id_list = table_df[global_key].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPChwEbVTPMQ"
   },
   "outputs": [],
   "source": [
    "# переводим картинки из списка в формат PIL\n",
    "image_list = to_pool(img_list, eval('file2PIL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPQVO2Hiu6rh"
   },
   "outputs": [],
   "source": [
    "# оставляем тольк первые изображения\n",
    "image_list = list(filter(lambda item: filterImgPreff(item['title'], [1, '1']), image_list))\n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yJBRH_agh1X0"
   },
   "outputs": [],
   "source": [
    "data_img =  pd.DataFrame(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikJ4qtgtef7K"
   },
   "outputs": [],
   "source": [
    "# добавляем колонку с id по которому матчим таблицы\n",
    "image_num_list = to_pool(data_img['title'].tolist(), eval('getImgId'))\n",
    "data_img[global_key] = image_num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMt8D1XeHOmj"
   },
   "source": [
    "#### Эталонные картинки для центройдов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbt7-5Jcr2nf"
   },
   "outputs": [],
   "source": [
    "# соединяет таблицу изображений и таблицу сюжетов по ключевому полю\n",
    "\n",
    "# df_plot - датафрейм с сюжетами, df_img - датафрейм с изображениями\n",
    "# loc_key = '' - название столбца по которому соединяются таблицы (если не указан - 'regNumber')\n",
    "def setPlotImg(df_plot, df_img, loc_key = ''):\n",
    "  key = loc_key if loc_key else global_key\n",
    "  key_plot_list = np.unique(df_plot[key].tolist())\n",
    "  df_temp = df_img.loc[df_img[key].isin(key_plot_list)]\n",
    "\n",
    "  return df_plot.merge(df_temp, on=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eVjz3QkqHU6S"
   },
   "outputs": [],
   "source": [
    "# создаем список сюжето\n",
    "plot_table_df = csv2DF('plot_list')\n",
    "plot_table_df =  plot_table_df[[global_key, 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nj9psSVZTYQG"
   },
   "outputs": [],
   "source": [
    "# создаем словарь сюжетов\n",
    "plot_list = np.unique(plot_table_df['name'].tolist())\n",
    "\n",
    "plot_dictionary = {plot_list[i]:str(i) for i in range(0, len(plot_list))}\n",
    "# добавляем номер сюжета по словарю\n",
    "plot_table_df['plot_id'] = plot_table_df['name'].map(plot_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgLAHVclNGjW"
   },
   "outputs": [],
   "source": [
    "plot_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N51Q0pxeL11L"
   },
   "outputs": [],
   "source": [
    "# У нас совпадают ID картинок для двух сюжетов\n",
    "# В каталоге это лист с несколькими гравюрами https://goskatalog.ru/portal/#/collections?id=34450495\n",
    "plot_table_df[plot_table_df[global_key] == 34251283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ueerai62MNpy"
   },
   "outputs": [],
   "source": [
    "# Выкидываю из списка пока оба сюжета\n",
    "plot_table_df = plot_table_df.loc[~plot_table_df[global_key].isin([34251283])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIDEpinxJnFQ"
   },
   "outputs": [],
   "source": [
    "print(f'Всего сюжетов {len(plot_table_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXSR69GHHiZT"
   },
   "source": [
    "#### Валидационная выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JS6ult0we4FB"
   },
   "outputs": [],
   "source": [
    "# валидационная выборка\n",
    "valid_table_df = csv2DF('sample_objects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQxFJ4q6hUsF"
   },
   "outputs": [],
   "source": [
    "# убираем из валидационной выборки connectedness = 0 и plot = NaN\n",
    "values_list = [0.0]\n",
    "valid_table_df = valid_table_df[~valid_table_df['connectedness'].isin(values_list)]\n",
    "valid_table_df = valid_table_df[valid_table_df['plot'].notna()]\n",
    "valid_table_df = valid_table_df[['name' ,'regNumber','plot']]\n",
    "\n",
    "# добавляем номер сюжета по словарю\n",
    "valid_table_df['label_true'] = valid_table_df['plot'].map(plot_dictionary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qj1QS4NFa6au"
   },
   "outputs": [],
   "source": [
    "valid_table_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2GTD-uVU1NJ"
   },
   "outputs": [],
   "source": [
    "# удаляем афишу выставки Русские гравюры 18 века по рисункам Михаила Махаева, поскольку сюжета такого нет )\n",
    "valid_table_df = valid_table_df[valid_table_df['label_true'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00LZaPkFfVSg"
   },
   "outputs": [],
   "source": [
    "valid_id_list = valid_table_df[global_key].tolist()\n",
    "plots_in_valid_table_df = np.unique(valid_table_df['label_true'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ceSSiSiEuja"
   },
   "outputs": [],
   "source": [
    "# Распределение сюжетов, представленных в выборке\n",
    "plots_in_valid_table_dict = dict(Counter(valid_table_df['plot']))\n",
    "\n",
    "# сюжеты, для которых в выборке больше 2 объектов\n",
    "common_plots_in_valid_table = dict(filter(lambda x: x[1] >= 2, plots_in_valid_table_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZAmr0IMC1lo"
   },
   "outputs": [],
   "source": [
    "print(f'Всего сюжетов: {len(plot_table_df)}')\n",
    "print(f'Количество сюжетов, представленных в выборке: {len(plots_in_valid_table_df)}')\n",
    "print(f'Количество сюжетов, представленных в выборке для которых количество объектов больше или = 2:{len(common_plots_in_valid_table)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJ2ZDv4gRmme"
   },
   "outputs": [],
   "source": [
    "lemit = 10\n",
    "print(f'{lemit} самых распространенных сюжета:')\n",
    "print(*list(dict(sorted(plots_in_valid_table_dict.items(), key=lambda item: item[1], reverse=True)).items())[0:lemit], sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLbhg02XFfJs"
   },
   "source": [
    "Выводы:\n",
    "- в валидационной выборке представленны не все сюжеты\n",
    "- почти половина сюжетов представленны в выборке 1 объектом, следовательно такие алгоритмы кластаризации, как DBSCAN отнесут их в \"мусор\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCp1MrE6QFGQ"
   },
   "source": [
    "## Обработка картинок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWHP0yUchuhe"
   },
   "source": [
    "### Тензор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNhRsx26k7-q"
   },
   "outputs": [],
   "source": [
    "# импорт из clip нужного\n",
    "import requests\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from transformers import AutoProcessor, CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65E8VHiA3xSj"
   },
   "outputs": [],
   "source": [
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKpssc1ohwuz"
   },
   "outputs": [],
   "source": [
    "# получает тензор изображения с помощью clip-model\n",
    "# возвращает обект типа tensor()\n",
    "\n",
    "# image - вектор изображения формата PIL\n",
    "def image_features_get(image):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "\n",
    "    return image_features.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_RtRYDupBmm"
   },
   "outputs": [],
   "source": [
    "features_list = to_pool(data_img['img'].tolist(), eval('image_features_get'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByISdR7io-Dt"
   },
   "outputs": [],
   "source": [
    "#reshape\n",
    "features_list_reshape = [t.detach().numpy().reshape(-1) for t in features_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rh9i0NIKE3rQ"
   },
   "outputs": [],
   "source": [
    "data_img['features'] = features_list_reshape\n",
    "data_img.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5MJCdFzItsy7"
   },
   "outputs": [],
   "source": [
    "# создаем список ключевых изображений\n",
    "data_key_img = setPlotImg(plot_table_df, data_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k05YKhYR3ari"
   },
   "outputs": [],
   "source": [
    "# проверяем, что нашли все ключевые изображения\n",
    "key_plot_list_in_img = data_key_img[global_key].tolist()\n",
    "plot_table_df[~plot_table_df[global_key].isin(key_plot_list_in_img)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3iTpxGKYx4DE"
   },
   "outputs": [],
   "source": [
    "# отделяем трейн и тест выборки\n",
    "data_img_valid = data_img.loc[data_img[global_key].isin(valid_id_list)].copy()\n",
    "\n",
    "data_img_test = data_img.loc[~data_img[global_key].isin(valid_id_list)].copy()\n",
    "# отделяем \"чистую выборку\" (без conntents=0)\n",
    "data_img_clear = data_img_test.loc[data_img_test[global_key].isin(clear_id_list)].copy()\n",
    "print(f'Длина валидационной выборки: {len(data_img_valid)}. Длина общей выборки: {len(data_img_test)}. Длина очищенной выборки: {len(data_img_clear)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lu7lDzDbnYFi"
   },
   "outputs": [],
   "source": [
    "# для трейна прописываем label\n",
    "label_true = to_pool(data_img_valid.to_dict(orient='records'), eval('setTrueLabel'))\n",
    "data_img_valid['label_true'] = label_true\n",
    "data_img_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ioz9Q_qjy71"
   },
   "outputs": [],
   "source": [
    "train = data_img_valid['features'].tolist()\n",
    "probs =  data_img_test['features'].tolist()\n",
    "probs_clear = data_img_clear['features'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IQ-CmsPgaYE7"
   },
   "outputs": [],
   "source": [
    "labels_true = data_img_valid['label_true'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdsoWqXBI1Qr"
   },
   "source": [
    "## Общее для кластаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shLimkobJAOM"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import normalize, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF8YFGaZZTHl"
   },
   "outputs": [],
   "source": [
    "global_score_funcs = [\n",
    "    #(\"V-measure\", metrics.v_measure_score),\n",
    "    #(\"Rand index\", metrics.rand_score),\n",
    "    (\"ARI\", metrics.adjusted_rand_score),\n",
    "    #(\"MI\", metrics.mutual_info_score),\n",
    "    #(\"NMI\", metrics.normalized_mutual_info_score),\n",
    "    (\"AMI\", metrics.adjusted_mutual_info_score),\n",
    "    (\"Однородность, Полнота, V-мера\", metrics.homogeneity_completeness_v_measure)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nt3CUVWC-u24"
   },
   "outputs": [],
   "source": [
    "# выводим метрику в табличной форме\n",
    "def metricsRezult_forDF(metric_list):\n",
    "    rezult_dict = {}\n",
    "\n",
    "    for item in metric_list:\n",
    "        if isinstance(item['score'], tuple):\n",
    "              score_title_list = item['score_name'].split(',')\n",
    "              for i in range(len(item['score'])):\n",
    "                  rezult_dict[score_title_list[i]] = item['score'][i]\n",
    "        else:\n",
    "            rezult_dict[item['score_name']]=item['score']\n",
    "    return rezult_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sdPjqmI0ZLNX"
   },
   "outputs": [],
   "source": [
    "# возвращает результаты проверки кластеризации различными метриками\n",
    "# x- предсказанные метки, y - истинные метки\n",
    "# score_funcs_list - список кортежей формата (название_функции, функция)\n",
    "def getMetricsRezult(x, y, score_funcs_list):\n",
    "    rezult_list = []\n",
    "    for func in score_funcs_list:\n",
    "        score_func = func[1]\n",
    "        score_name = func[0]\n",
    "        rezult = score_func(y, x)\n",
    "        rezult_list.append({'score_name': score_name, 'score':rezult})\n",
    "    return rezult_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqsVflBGbkJj"
   },
   "outputs": [],
   "source": [
    "# выводит на печать результаты кластаризации\n",
    "\n",
    "# labels - список полученных лейблов\n",
    "def print_сlustering_param(labels):\n",
    "  n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "  n_noise_ = list(labels).count(-1)\n",
    "  print(f'Количество кластеров : {n_clusters_}. Количество шума: {n_noise_} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NphYPeNkO5DJ"
   },
   "outputs": [],
   "source": [
    "# выводит на печать словарь вида {кластер:количество элементов в нем}\n",
    "\n",
    "# labels - список лейблов\n",
    "def print_claster(df, label, sampel_size = 30, suptitle = '', cv2_img = False, name = False):\n",
    "  rezult_df = df[df['labels'] == label].to_dict(orient='records')\n",
    "  if len(rezult_df) > sampel_size:\n",
    "     show_img(sample(rezult_df, sampel_size), name = name, suptitle = suptitle, cv2_img = cv2_img)\n",
    "  else:\n",
    "     show_img(rezult_df, name = name, suptitle = suptitle, cv2_img = cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNX4vKEOX78N"
   },
   "outputs": [],
   "source": [
    "# выводит на печать изображения по всем кластерам\n",
    "# df - датафрейм с столбцами 'img' (вектор изображения PIL или CV2), 'title' (заголовок), 'labels' (присвоенный класс)\n",
    "# sampel_size = 30 - максимальный размер выборки изображений,\n",
    "# cv2_img = False - булеан использовать формат cv2 или нет,\n",
    "# name = False -  булеан печатать имя картинки или нет,\n",
    "def print_img_in_classters(df, cv2_img = False, sampel_size = 30, suptitle = '', name = False):\n",
    "    for k in np.unique(df['labels']):\n",
    "        df_temp = df[df['labels'] == k]\n",
    "        suptitle = '-'.join([str(k), str(len(df_temp))])\n",
    "        print_claster(df, k, suptitle = suptitle, sampel_size = sampel_size, cv2_img = cv2_img , name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lrxq_Rmtednd"
   },
   "outputs": [],
   "source": [
    "# выводит на печать словарь вида {кластер:количество элементов в нем}\n",
    "\n",
    "# labels - список лейблов\n",
    "def print_claster_count(labels):\n",
    "    return  dict(Counter(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p89VjtDu6AjS"
   },
   "outputs": [],
   "source": [
    "# выводит на печать картинки из переданного списка, согласно кластаризации\n",
    "# или печатает только один класс, если есть ключ кластера\n",
    "\n",
    "# img_df - дата фрейм с колонками 'img' - типа PIC/CV, 'title' - имя картинки = ссылка на картинку в выгрузке\n",
    "# labels - список лейблов\n",
    "# key - ключ кластера\n",
    "# printOneClaster = False, - печатаем все или только выбранный кластер\n",
    "# sampel_size = 30, suptitle = '', cv2_img = False, name = False - параметры печати\n",
    "def printVizual(img_df, labels, key=False, printOneClaster = False, sampel_size = 30, suptitle = '', cv2_img = False, name = False):\n",
    "    df_temp = pd.DataFrame({'img': img_df['img'], 'title': img_df['title'], 'labels':labels})\n",
    "    if printOneClaster:\n",
    "       print_claster(df_temp, key, sampel_size = sampel_size, suptitle = suptitle, cv2_img = cv2_img, name =name)\n",
    "    else:\n",
    "       print_img_in_classters(df_temp, sampel_size = sampel_size, suptitle = suptitle, cv2_img = cv2_img, name =name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kewgXmPW9RzK"
   },
   "outputs": [],
   "source": [
    "def save_claster_rezult(img_df, labels, param):\n",
    "    df_rezult = pd.DataFrame({global_key: img_df[global_key], 'title': img_df['title'], 'img': img_df['img'], 'labels':labels})\n",
    "    save2csv(df_rezult, param=param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jx4224IgKuf3"
   },
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8Tl-ryAJOsT"
   },
   "source": [
    "### Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hwg5HBNGKyqm"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYoJrDMN6i9N"
   },
   "outputs": [],
   "source": [
    "# применяет DBSCAN с переданными параметрами\n",
    "# возвращает список полученных лейблов\n",
    "\n",
    "# X - список фичей,\n",
    "# eps=0.1, min_samples=4, metric='cosine' - параметры DBSCAN,\n",
    "# (подробней https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)\n",
    "# scale  -   булево значение стандартизировать или нет перед применение DBSCAN\n",
    "# norm  -   булево значение нормализовать или нет перед применение DBSCAN\n",
    "def get_dbscan_label_test(X, eps=0.1, min_samples=4, metric='cosine', scale = True, norm = True):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric)\n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    db.fit(X)\n",
    "    return db.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKWYPqNE6R7H"
   },
   "source": [
    "##### Табличный вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrsFf4nb6SnN"
   },
   "outputs": [],
   "source": [
    "# вывод DF с результатами работа DBSCAN в табличной форме\n",
    "def rezult_DF_DBSCAN(klaster_list, printTitle = True, printCounter = True, printScore = False):\n",
    "    rezult_list = []\n",
    "\n",
    "    for item in klaster_list:\n",
    "        row_dict = {}\n",
    "\n",
    "        if printTitle:\n",
    "           row_dict.update({'title':item['title']})\n",
    "\n",
    "        row_dict.update({\n",
    "            'data':item['data_type'],\n",
    "            'min_samples':item['min_samples'],\n",
    "            'eps':item['eps']\n",
    "        })\n",
    "\n",
    "        count = dict(Counter(item['labels']))\n",
    "        n_noise_ = list(item['labels']).count(-1)\n",
    "        row_dict.update({'class':len(count) - 1,  'noise':n_noise_})\n",
    "        if printScore:\n",
    "           current_metric_list = item['score']\n",
    "           row_dict.update(metricsRezult_forDF(current_metric_list))\n",
    "        if printCounter:\n",
    "           row_dict.update({'counter':count})\n",
    "\n",
    "        rezult_list.append(row_dict)\n",
    "\n",
    "    return pd.DataFrame(rezult_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SigQzuA_R5v_"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aeb4sxeFJIq-"
   },
   "outputs": [],
   "source": [
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5Mksc_aceWF"
   },
   "outputs": [],
   "source": [
    "# метод для нахождения оптимального eps для DBSCAN,\n",
    "# используется для дальнейшего построения графика \"колена\"\n",
    "# возвращает средние дистанции между точками набора, полученные методом NearestNeighbors\n",
    "\n",
    "# X - список фичей,\n",
    "# num = 21 -  параметр earestNeighbors, количество соседей = MinPts, которое будет использоваться в DBSCAN,\n",
    "# print_plt = False - булево значение печать график или нет\n",
    "# scale  -   булево значение стандартизировать или нет перед применение NearestNeighbors\n",
    "# norm  -   булево значение нормализовать или нет перед применение NearestNeighbors\n",
    "\n",
    "def get_neighbors(X, num = 11, print_plt = False, scale = True, norm = True):\n",
    "  neigh = NearestNeighbors(n_neighbors=num)\n",
    "  if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "  if norm:\n",
    "       X = normalize(X)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors(X)\n",
    "  distances = np.sort(distances[:,num-1], axis=0)\n",
    "  if print_plt:\n",
    "     fig = plt.figure(figsize = (18, 9))\n",
    "     plt.plot(distances)\n",
    "     plt.xlabel('Points')\n",
    "     plt.ylabel('Distance')\n",
    "\n",
    "  return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZz6u8szJKlw"
   },
   "outputs": [],
   "source": [
    "# возвращает значенеи \"колена\"\n",
    "\n",
    "# dist - дистанции между соседями, полученные методом NearestNeighbors\n",
    "# print_plt = False - булево значение печать график или нет\n",
    "def get_kneeLocatore(dist, S=1.0, online=False, print_plt = False):\n",
    "    x, y = np.arange(len(dist)), dist\n",
    "    kneedle = KneeLocator(x, y, S=S, curve=\"convex\", direction=\"increasing\", online=online)\n",
    "    if print_plt:\n",
    "       kneedle.plot_knee_normalized()\n",
    "\n",
    "    knee_point = kneedle.knee\n",
    "    elbow_point = kneedle.elbow\n",
    "    return knee_point, elbow_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZfTqKvT-_bs"
   },
   "outputs": [],
   "source": [
    "#  результаты кластерезации методом DBSCAN с различными параметрами\n",
    "# возвращает лист словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера, 'n_clusters_':количество кластеров, 'n_noise_':количество шума}\n",
    "# отсортированный по возрастанию шума\n",
    "\n",
    "# X - список фичей,\n",
    "# param_list - список словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера}\n",
    "# min_claster_count = 2 - минимальное количество кластеров, которое должно получится в выборке\n",
    "# getScore = False - печатать оценку кластеризации\n",
    "# Y='' - список классов для валидации\n",
    "# score_funcs_list = '' - список кортежей формата (название_функции, функция) (по умолчанию global_score_funcs)\n",
    "def get_dbscan_test(X, param_list, min_claster_count = 2, getScore = False, Y='', score_funcs_list = ''):\n",
    "    rezult = []\n",
    "    for row in param_list:\n",
    "       min_samples = row['min_samples']\n",
    "       eps = row['eps']\n",
    "       labels =  get_dbscan_label_test(X, eps=eps, min_samples=min_samples)\n",
    "       n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "       n_noise_ = list(labels).count(-1)\n",
    "       if getScore:\n",
    "          score_funcs_list = score_funcs_list if score_funcs_list else global_score_funcs\n",
    "          rezult.append({'eps':eps, 'min_samples':min_samples, 'n_clusters_':n_clusters_, 'n_noise_':n_noise_, 'score_list':getMetricsRezult(labels, Y, score_funcs_list)})\n",
    "       else:\n",
    "          rezult.append({'eps':eps, 'min_samples':min_samples, 'n_clusters_':n_clusters_, 'n_noise_':n_noise_})\n",
    "\n",
    "    rezult = list(filter(lambda item: item['n_clusters_'] > min_claster_count, rezult))\n",
    "    rezult = sorted(rezult, key=lambda item: item['n_noise_'])\n",
    "\n",
    "    return rezult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5_lZawFA9dg"
   },
   "outputs": [],
   "source": [
    "# печатает результаты кластерезации методом DBSCAN с различными параметрами\n",
    "\n",
    "# X - список фичей,\n",
    "# param_list - список словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера}\n",
    "# getScore = False - печатать оценку кластеризации\n",
    "# Y='' - список классов для валидации\n",
    "# score_funcs_list = '' - список кортежей формата (название_функции, функция) (по умолчанию global_score_funcs)\n",
    "def print_dbscan_test(X, param_list, getScore = False, Y='', score_funcs_list = ''):\n",
    "    for row in param_list:\n",
    "       min_samples = row['min_samples']\n",
    "       eps = row['eps']\n",
    "       labels =  get_dbscan_label_test(X, eps=eps, min_samples=min_samples)\n",
    "\n",
    "       n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "       n_noise_ = list(labels).count(-1)\n",
    "       print(f'eps={eps}, min_samples={min_samples}')\n",
    "       print(f'Количество кластеров : {n_clusters_}. Количество шума: {n_noise_} ')\n",
    "       print(print_claster_count(labels))\n",
    "       if getScore:\n",
    "          score_funcs_list = score_funcs_list if score_funcs_list else global_score_funcs\n",
    "          score_list = getMetricsRezult(labels, Y, score_funcs_list)\n",
    "          print(*score_list, sep='\\n')\n",
    "       print('+'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5wlxhmFRPK9x"
   },
   "outputs": [],
   "source": [
    "# создает список параметров и проводит для них тестирование DBSCAN\n",
    "# в зависимости от флага выводит на печать результаты\n",
    "# возвращает лист словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера, 'n_clusters_':количество кластеров, 'n_noise_':количество шума}\n",
    "# отсортированный по возрастанию шума\n",
    "\n",
    "# X - список фичей,\n",
    "# eps_list - список eps для которых будет формироваться лист параметров\n",
    "# samples_list = [3, 4] - список min_samples для которых будет формироваться лист параметров\n",
    "# print=False - булево значение печатать результаты тестов\n",
    "# getScore = False - печатать оценку кластеризации\n",
    "# Y='' - список классов для валидации\n",
    "# score_funcs_list = '' - список кортежей формата (название_функции, функция) (по умолчанию global_score_funcs)\n",
    "def set_dbscan_param(X, eps_list, samples_list = [3, 4], print=False, getScore = False, Y=''):\n",
    "    min_samples_list = []\n",
    "    for i in samples_list:\n",
    "        min_samples_list = min_samples_list + len(eps_list) * [i]\n",
    "    param_list = pd.DataFrame(list(zip(eps_list*len(samples_list), min_samples_list)),columns =['eps', 'min_samples']).to_dict(orient='records')\n",
    "    if print:\n",
    "       print_dbscan_test(X, param_list, getScore = getScore, Y=Y)\n",
    "    else:\n",
    "       return get_dbscan_test(X, param_list, getScore = getScore, Y=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLJ79oTFeFvC"
   },
   "source": [
    "### На валидационной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3tFvvcuSlPI"
   },
   "source": [
    "#### Оптимальные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pgPQ1HwjOnV"
   },
   "outputs": [],
   "source": [
    "best_eps = 0.541\n",
    "best_sample = 2\n",
    "\n",
    "labels_1 = get_dbscan_label_test(train, eps = best_eps, min_samples=best_sample)\n",
    "print_сlustering_param(labels_1)\n",
    "print(print_claster_count(labels_1))\n",
    "getMetricsRezult(labels_1, labels_true, global_score_funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQTICNJDziFR"
   },
   "outputs": [],
   "source": [
    "test_rezult_list_DBSCAN = [\n",
    "    {\n",
    "                'title':'с лучшими значениями метрик на валидационной',\n",
    "                'eps': best_eps,\n",
    "                'min_samples': best_sample,\n",
    "                'data_type': 'валидационная',\n",
    "                'labels': labels_1,\n",
    "                'score': getMetricsRezult(labels_1, labels_true, global_score_funcs)\n",
    "               }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lp_l1H7M3dXx"
   },
   "outputs": [],
   "source": [
    "df_table = rezult_DF_DBSCAN(test_rezult_list_DBSCAN, printScore = True, printCounter =False, printTitle =False)\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbblrWiNyOjm"
   },
   "source": [
    "#### Визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w16u_3BvWx3p"
   },
   "source": [
    "Видно, что распределение по кластерам более равномерное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxfsce7emjt8"
   },
   "outputs": [],
   "source": [
    "printVizual(data_img_valid, labels_1, sampel_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUBiyULIyaAS"
   },
   "outputs": [],
   "source": [
    "#bad\n",
    "plan_num = 0\n",
    "printVizualCollag(data_img_valid, labels_1, plan_num, size = (256, 256), cols = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NW1CDXjV8kv"
   },
   "outputs": [],
   "source": [
    "plan_num = 9\n",
    "printVizual(data_img_valid, labels_1, printOneClaster = True, key = plan_num, sampel_size = 200, suptitle = 'План Петербурга 1753.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61rk9xinWU93"
   },
   "outputs": [],
   "source": [
    "ramka_klaster = 0\n",
    "printVizual(data_img_valid, labels_1, printOneClaster = True, sampel_size = 200, key = ramka_klaster, suptitle = 'Гравюры с рамкой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qRTDfFyXQcS"
   },
   "outputs": [],
   "source": [
    "list_klaster = 2\n",
    "printVizual(data_img_valid, labels_1, printOneClaster = True, key = list_klaster, sampel_size = 200, suptitle = 'Гравюра на листе')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbamvpZdut5e"
   },
   "source": [
    "Для тестовой выборки вариант с eps=0.541 и min_sampel = 2 показывает лучшие значения по метрикам.\n",
    "\n",
    "- Хорошо определил кластер с 'План Петербурга 1753' (почти все 20 из 21 в выборке)\n",
    "- Проблема - воспринимает как отдельные кластеры гравюры с рамкой и подписью и небольшие гравюры посередине листа в независимости от сюжета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFW3bdTH9Qt6"
   },
   "source": [
    "#### Сохранение результатов с лучшими параметрами класстаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vooJ_q-19-Lr"
   },
   "outputs": [],
   "source": [
    "save_claster_rezult(data_img_valid, labels_1, param='DBSCAN_valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbAvhGqcEiTl"
   },
   "source": [
    "### На тесте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlHpIX_rSZP5"
   },
   "source": [
    "###### Оптимальные параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPXLptMLTxtt"
   },
   "source": [
    "Поскольку мы знаем количество сюжетов в выборке (95) оринтируясь на количество кластеров оптимальным по соотношению количество кластеров/количество шума выглядит\n",
    "\n",
    "Для не очищенной выборки:\n",
    "eps = 0.382, min_samples = 2\n",
    "(Количество кластеров: 92, Количество шума: 259)\n",
    "\n",
    "Для очищенной:\n",
    "eps=0.387, min_samples=2\n",
    "(Количество кластеров : 94. Количество шума: 241)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VEQ9-bQTyY9"
   },
   "outputs": [],
   "source": [
    "best_eps_test =  0.382\n",
    "best_sample_test = 2\n",
    "best_eps_test_clear =  0.387\n",
    "best_sample_test_clear = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jeYxqFbEkj3"
   },
   "outputs": [],
   "source": [
    "test_rezult_DBSCAN = {'Выборка с лучшими значениями метрик на валидационной выборки':get_dbscan_label_test(probs, eps = best_eps, min_samples=best_sample),\n",
    "               'Выборка чистая с лучшими значениями метрик на валидационной выборки':get_dbscan_label_test(probs_clear, eps = best_eps, min_samples=best_sample),\n",
    "               'Выборка с оптимальными значениями eps/min_samples на общей выборке':get_dbscan_label_test(probs, eps = best_eps_test, min_samples=best_sample_test),\n",
    "               'Выборка чистая с оптимальными значениями eps/min_samples на чистой выборке':get_dbscan_label_test(probs_clear, eps = best_eps_test_clear, min_samples=best_sample_test_clear)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps-LxJQiFiJQ"
   },
   "outputs": [],
   "source": [
    "list_test_rezult_DBSCAN = []\n",
    "for k, v in test_rezult_DBSCAN.items():\n",
    "    print(f'{k}')\n",
    "    count = Counter(v)\n",
    "    print(f'Количество классов {len(count) - 1}') # поскольку один класс это \"мусор\"\n",
    "    print(count)\n",
    "    list_test_rezult_DBSCAN.append({'title':k, 'labels':v, 'count':dict(count)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exh7O5fDuGkb"
   },
   "outputs": [],
   "source": [
    "test_rezult_list_DBSCAN = [{\n",
    "                'title':'с лучшими значениями метрик на валидационной',\n",
    "                'eps': best_eps,\n",
    "                'min_samples': best_sample,\n",
    "                'data_type': 'полная',\n",
    "                'labels': list_test_rezult_DBSCAN[0]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'с лучшими значениями метрик на валидационной',\n",
    "                'eps': best_eps,\n",
    "                'min_samples': best_sample,\n",
    "                'data_type': 'чистая',\n",
    "                'labels':list_test_rezult_DBSCAN[1]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'с лучшими значениями метрик на тесте',\n",
    "                'eps': best_eps_test,\n",
    "                'min_samples': best_sample_test,\n",
    "                'data_type': 'полная',\n",
    "                'labels':list_test_rezult_DBSCAN[2]['labels'],\n",
    "               },\n",
    "               {\n",
    "                'title':'с лучшими значениями метрик на тесте',\n",
    "                'eps': best_eps_test_clear,\n",
    "                'min_samples': best_sample_test_clear,\n",
    "                'data_type': 'чистая',\n",
    "                'labels':list_test_rezult_DBSCAN[3]['labels'],\n",
    "               }\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "azNVrDU1vNKN"
   },
   "outputs": [],
   "source": [
    "df_table = rezult_DF_DBSCAN(test_rezult_list_DBSCAN, printCounter =False)\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YU1cdkae09a"
   },
   "source": [
    "Очевидно, что значения eps/min_samples, полученные на валидационной выборке, плохо себя показали на общей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DccxjlHJaor"
   },
   "source": [
    "###### Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "sNdbpzaGu-Je",
    "outputId": "e4afc2a8-b0e6-4f1c-a3c1-9dbf1ecb92bc"
   },
   "outputs": [],
   "source": [
    "# визуализируем результаты - Выборка с оптимальными значениями eps/min_samples на общей выборке\n",
    "printVizual(data_img_test, list_test_rezult_DBSCAN[2]['labels'], suptitle = list_test_rezult_DBSCAN[2]['title'], sampel_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "db4fk6S_FuZr"
   },
   "outputs": [],
   "source": [
    "# визуализируем результаты - Выборка чистая с оптимальными значениями eps/min_samples на чистой выборке\n",
    "printVizual(data_img_clear, list_test_rezult_DBSCAN[3]['labels'], suptitle = list_test_rezult_DBSCAN[0]['title'], sampel_size = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp2OVyQ1vE5i"
   },
   "source": [
    "Также как на валидационной выборке, лучше всего выделяются планы и карты. Есть несколько кластеров объединенных по форме (гравюра на странице, открытка, печатный текст), а не по сюжету."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hu7pUMOWt7jo"
   },
   "source": [
    "###### Сохранение результатов с лучшими параметрами класстаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8CvuaNsuJV-"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "      list_test_rezult_DBSCAN[2]['title'],\n",
    "      list_test_rezult_DBSCAN[3]['title'], sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rH73o9Kqt6Jw"
   },
   "outputs": [],
   "source": [
    "save_claster_rezult(data_img_test, list_test_rezult_DBSCAN[2]['labels'], param='DBSCAN_full')\n",
    "save_claster_rezult(data_img_clear, list_test_rezult_DBSCAN[3]['labels'], param='DBSCAN_clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FffVZ9y-GxHH"
   },
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wtTKY8-NG1ia"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOGsWi-vJsPj"
   },
   "outputs": [],
   "source": [
    "# применяет KMeans с переданными параметрами\n",
    "# возвращает список полученных лейблов\n",
    "\n",
    "# X - список фичей,\n",
    "# k - количество кластеров,\n",
    "# n_init= 'auto', random_state=1 - параметры KMeans\n",
    "# scale  -   булево значение стандартизировать или нет перед применение KMeans\n",
    "# norm  -   булево значение нормализовать или нет перед применение KMeans\n",
    "# use_centroids = False - использовать переданный массив центройдов\n",
    "# centroids = '' - центройды\n",
    "def get_KMeans_labels(X, k=0, scale = True, norm = True, use_centroids = False, centroids = '', init=\"k-means++\", n_init= 'auto', random_state=1):\n",
    "    if use_centroids:\n",
    "       # если передаем центройды\n",
    "       n_clusters= k if k != 0 else len(centroids)\n",
    "       kmeans = KMeans(n_clusters=max(2, n_clusters), init=centroids, n_init=1, random_state=random_state)\n",
    "    else:\n",
    "       kmeans = KMeans(init= init, n_clusters=max(k,2), n_init=n_init, random_state=random_state)\n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    kmeans.fit(X)\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiHl8Er_lUtn"
   },
   "source": [
    "### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odfC_4y7lnI-"
   },
   "outputs": [],
   "source": [
    "# нахождение оптимального количества кластеров для KMeans,\n",
    "# методом силуэта\n",
    "# возвращает средние значение силуэта для выбранного количества кластеров\n",
    "\n",
    "# X - список фичей,\n",
    "# num = 10 -  параметр KMeans, количество примененеий метода для рассчета среднего значения силуэта,\n",
    "# scale  -   булево значение стандартизировать или нет перед применение KMeans\n",
    "# norm  -   булево значение нормализовать или нет перед применение KMeans\n",
    "def get_KMeans_silhouette_score(X, k, num = 10, scale = True, norm = True, init=\"k-means++\", metric='cosine'):\n",
    "    kmeans = KMeans(init= init, n_clusters=max(k,2), n_init= 'auto', random_state=num)\n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels, metric=metric)\n",
    "\n",
    "    return silhouette_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBjgxaHu5819"
   },
   "source": [
    "#### Табличный вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DL8F1pw559wN"
   },
   "outputs": [],
   "source": [
    "def rezult_DF_test(klaster_list, num = 10, scale = True, norm = True, printCounter = True):\n",
    "    rezult_list = []\n",
    "\n",
    "    for item in klaster_list:\n",
    "        row_dict = {}\n",
    "        count = dict(Counter(item['labels']))\n",
    "        X = item['data']\n",
    "        row_dict.update({'title':item['title'],'class':len(count), 'data':item['data_type'],'counter':count})\n",
    "        if printCounter:\n",
    "           row_dict.update({'counter':count})\n",
    "\n",
    "        row_dict['silhouette_score'] = get_KMeans_silhouette_score(X, len(count), num = num, scale = scale, norm = norm)\n",
    "\n",
    "        rezult_list.append(row_dict)\n",
    "\n",
    "    return pd.DataFrame(rezult_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sBrR0JO6B0k"
   },
   "outputs": [],
   "source": [
    "def rezult_DF(klaster_dict_list, X, y, num = 10, scale = True, norm = True, title_list = [], printCounter = True, printSilhouet = True):\n",
    "    rezult_list = []\n",
    "    for klaster_dict in klaster_dict_list:\n",
    "      for k, v in klaster_dict.items():\n",
    "          row_dict = {}\n",
    "\n",
    "          row_dict.update({'class':k})\n",
    "\n",
    "          if printCounter:\n",
    "             row_dict.update({'counter':dict(Counter(v))})\n",
    "          if printSilhouet:\n",
    "             row_dict.update({'silhouette_score':get_KMeans_silhouette_score(X, k, num = num, scale = scale, norm = norm)})\n",
    "          current_metric_list = getMetricsRezult(v, y, global_score_funcs)\n",
    "          row_dict.update(metricsRezult_forDF(current_metric_list))\n",
    "\n",
    "          rezult_list.append(row_dict)\n",
    "    df_rezult = pd.DataFrame(rezult_list)\n",
    "    if len(title_list) != 0:\n",
    "       df_rezult.insert(0, 'title', title_list)\n",
    "\n",
    "\n",
    "    return df_rezult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jtHbrlwmlWu"
   },
   "outputs": [],
   "source": [
    "# рассчитывает значение силуэта для различных k в заданном диапазоне\n",
    "# возвращаем словарь вида {количество кластеров:значение силуэта}\n",
    "\n",
    "# X - список фичей,\n",
    "# start = 10, end = 110, step_list = [10, 5, 1] - диапазон в которых проверяме значения k и шаг с которым выполняем проверку\n",
    "# set_len = 3 - размер возвращаемого словаря\n",
    "# scale  -   булево значение стандартизировать или нет перед применение KMeans\n",
    "# norm  -   булево значение нормализовать или нет перед применение KMeans\n",
    "def get_klasters_set(X, start = 10, end = 110, step_list = [10, 5, 1], set_len = 3, scale = True, norm = True):\n",
    "    current_start = start\n",
    "    current_end = end\n",
    "    for step in step_list:\n",
    "        # считаем для каждого k значение силуэта\n",
    "        k_dict = {max(k, 2): get_KMeans_silhouette_score(X, k, scale = scale, norm = norm) for k in range(current_start, current_end, step)}\n",
    "        # сортируем результаты по значениям силуэта\n",
    "        k_dict = dict(sorted(k_dict.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "        # print(k_dict)\n",
    "        # берем два k с самыми высокими значениями и сортируем их по возрастанию k\n",
    "        # таким образом получаем новые значения current_start и current_end\n",
    "        param = sorted(list(k_dict.items())[0:2])\n",
    "        current_start, current_end = param[0][0], param[1][0] + 1\n",
    "\n",
    "    # берем первые значения из списка (по умолчанию - 3)\n",
    "    rezult = list(k_dict.items())[0:set_len]\n",
    "    # получем список кластеров\n",
    "    #return [i[0] for i in rezult]\n",
    "    return rezult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1NZONi1TRMv"
   },
   "source": [
    "### На валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TxPjQVO_rN7I"
   },
   "outputs": [],
   "source": [
    "# не нашла более разумного способа, поэтому отдельно считаем возможное количество кластеров от 2 до 10 и от 10 до 100\n",
    "k_dict = get_klasters_set(train) + get_klasters_set(train, start = 0, end = 10, step_list = [1])\n",
    "k_list = [i[0] for i in k_dict]\n",
    "k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IoPMC3CEqvUc"
   },
   "outputs": [],
   "source": [
    "# Поскольку знаем реальное количество сюжетов (95), добавим в конец списка это значение\n",
    "k_list.append(len(data_key_img))\n",
    "# Поскольку знаем реальное количество сюжетов в валидационной выборке (70), добавим в конец списка это значение\n",
    "k_list.append(len(plots_in_valid_table_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9m39o0-Tcqs"
   },
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(k_list, [get_KMeans_labels(train, k) for k in k_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0P4wrsC3zpA"
   },
   "outputs": [],
   "source": [
    "df_table = rezult_DF([labels_dict], X = train, y = labels_true, printCounter = False)\n",
    "df_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jgmld8g8USyz"
   },
   "outputs": [],
   "source": [
    "for k, v in labels_dict.items():\n",
    "    print(f'Количество классов {k}')\n",
    "    print(Counter(v))\n",
    "    print(getMetricsRezult(v, labels_true, global_score_funcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYbQIFIZTh0C"
   },
   "source": [
    "###### Оптимальные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiwiIXbqoZeK"
   },
   "outputs": [],
   "source": [
    "best_score_k = k_list[0]\n",
    "\n",
    "print(f'Количество классов {best_score_k}')\n",
    "score_list = getMetricsRezult(labels_dict[best_score_k], labels_true, global_score_funcs)\n",
    "print(*score_list, sep='\\n')\n",
    "print(f'Количество классов {len(plots_in_valid_table_df)}')\n",
    "score_list = getMetricsRezult(labels_dict[len(plots_in_valid_table_df)], labels_true, global_score_funcs)\n",
    "print(*score_list, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoXjHTVpLRoh"
   },
   "source": [
    "###### Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aezv_-PCumQy"
   },
   "outputs": [],
   "source": [
    "printVizual(data_img_valid, labels_dict[best_score_k], suptitle = 'Лучший score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klkrbGRR1Gvt"
   },
   "outputs": [],
   "source": [
    "printVizual(data_img_valid, labels_dict[len(plots_in_valid_table_df)], suptitle = 'По известному количесву сюжетов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDYeUszjw4ZO"
   },
   "source": [
    "##### Центройды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7es5OuAJnIV4"
   },
   "outputs": [],
   "source": [
    "centroids = pd.DataFrame(list(data_key_img['features'])).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNGp0myYnKJJ"
   },
   "source": [
    "Поскольку у нас отличается количество сюжетов в валидационной выборке и общее количество сюжетов, сделаем вариант только с центройдами из валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8D5L9ZLn8Ha"
   },
   "outputs": [],
   "source": [
    "data_key_img_short = data_key_img.loc[data_key_img['plot_id'].isin(plots_in_valid_table_df)]\n",
    "centroids_short = pd.DataFrame(list(data_key_img_short['features'])).to_numpy()\n",
    "len(data_key_img_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOQt4TgFw7pH"
   },
   "outputs": [],
   "source": [
    "labels_with_centroids_short = get_KMeans_labels(X = train, k = len(centroids_short), use_centroids = True, centroids=centroids_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jv3m3-urjyHD"
   },
   "outputs": [],
   "source": [
    "# сравниваем на том же количестве классов, но без установленных центройдов\n",
    "print(f'Количество классов {len(plots_in_valid_table_df)} с установленными центройдами')\n",
    "print(Counter(labels_with_centroids_short))\n",
    "score_list_centroids_short = getMetricsRezult(labels_with_centroids_short, labels_true, global_score_funcs)\n",
    "print(*score_list_centroids_short, sep='\\n')\n",
    "\n",
    "print(f'Количество классов {len(plots_in_valid_table_df)}')\n",
    "print(Counter(labels_dict[len(plots_in_valid_table_df)]))\n",
    "score_list = getMetricsRezult(labels_dict[len(plots_in_valid_table_df)], labels_true, global_score_funcs)\n",
    "print(*score_list, sep='\\n')\n",
    "\n",
    "print(f'Количество классов ({best_score_k}) с лучшими показателями метрики  без центройдов')\n",
    "print(Counter(labels_dict[best_score_k]))\n",
    "score_list = getMetricsRezult(labels_dict[best_score_k], labels_true, global_score_funcs)\n",
    "print(*score_list, sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GK2vC4GWC1l"
   },
   "outputs": [],
   "source": [
    "temp_dict_list = [\n",
    "              {len(centroids_short): labels_with_centroids_short},\n",
    "              {len(plots_in_valid_table_df): labels_dict[len(plots_in_valid_table_df)]},\n",
    "              {best_score_k: labels_dict[best_score_k]}\n",
    "]\n",
    "temp_title_list = [\n",
    "    'C центройдами',\n",
    "    'То же количество кластеров, без центройдов',\n",
    "    'С лучшими показателями метрики без центройдов'\n",
    "]\n",
    "df_table = rezult_DF(temp_dict_list, X = train, y = labels_true,  title_list = temp_title_list, printCounter = False)\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UdYff8Ll393"
   },
   "source": [
    "#### Визуализируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE3BQKZHncnK"
   },
   "outputs": [],
   "source": [
    "printVizual(data_img_valid, labels_with_centroids_short, suptitle = 'С установленными центройдами')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeUMM9fD0VEW"
   },
   "outputs": [],
   "source": [
    "printVizual(data_img_valid, labels_dict[len(plots_in_valid_table_df)], suptitle = 'Без центройдов')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_z-FibqvJEc"
   },
   "source": [
    "#### Сохранение результатов с лучшими параметрами класстаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cn68pjKHvKCM"
   },
   "outputs": [],
   "source": [
    "save_claster_rezult(data_img_valid, labels_dict[best_score_k], param='KMeans_valid')\n",
    "save_claster_rezult(data_img_valid, labels_with_centroids_short, param='KMeans_valid_centr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVGS576el3wj"
   },
   "source": [
    "### На тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VS6jXbIVweZ"
   },
   "outputs": [],
   "source": [
    "# найдем лучшее значение силуэта для полной и на чистой выборке\n",
    "k_dict_test = get_klasters_set(probs) + get_klasters_set(probs, start = 0, end = 10, step_list = [1])\n",
    "k_list_test = [i[0] for i in k_dict_test]\n",
    "\n",
    "k_dict_test_clear = get_klasters_set(probs_clear) + get_klasters_set(probs_clear, start = 0, end = 10, step_list = [1])\n",
    "k_list_test_clear = [i[0] for i in k_dict_test_clear]\n",
    "\n",
    "best_score_k_test = k_list_test[0]\n",
    "best_score_k_test_clear = k_list_test_clear[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0ndMQANll8B"
   },
   "outputs": [],
   "source": [
    "test_rezult = {'Выборка с установленными центройдами': get_KMeans_labels(X = probs, k = len(centroids), use_centroids = True, centroids=centroids),\n",
    "               'Выборка с количеством кластеров по числу сюжетов':get_KMeans_labels(X = probs, k = len(data_key_img)),\n",
    "               'Выборка с количеством кластеров с лучшими значениями метрик на валидационной выборке':get_KMeans_labels(X = probs, k = best_score_k),\n",
    "               'Выборка с лучшими значениями силуэта на тесте':get_KMeans_labels(X = probs, k = best_score_k_test),\n",
    "\n",
    "               'Выборка чистая с установленными центройдами': get_KMeans_labels(X = probs_clear, k = len(centroids), use_centroids = True, centroids=centroids),\n",
    "               'Выборка чистая с количеством кластеров по числу сюжетов':get_KMeans_labels(X = probs_clear, k = len(data_key_img)),\n",
    "               'Выборка чистая с количеством кластеров с лучшими значениями метрик на валидационной выборке':get_KMeans_labels(X = probs_clear, k = best_score_k),\n",
    "               'Выборка чистая с лучшими значениями силуэта на тесте': get_KMeans_labels(X = probs_clear, k = best_score_k_test_clear)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDs0IorqqZXJ"
   },
   "outputs": [],
   "source": [
    "list_test_rezult = []\n",
    "i = 0\n",
    "for k, v in test_rezult.items():\n",
    "    print(f'{i}. {k}')\n",
    "    count = Counter(v)\n",
    "    print(f'Количество классов {len(count)}')\n",
    "    print(count)\n",
    "    list_test_rezult.append({'title':k, 'labels':v, 'count':dict(count)})\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMLSee4IQtGp"
   },
   "outputs": [],
   "source": [
    "test_rezult = [{\n",
    "                'title':'C центройдами',\n",
    "                'data': probs,\n",
    "                'data_type': 'полная',\n",
    "                'labels': list_test_rezult[0]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'C количеством кластеров = числу сюжетов',\n",
    "                'data': probs,\n",
    "                'data_type': 'полная',\n",
    "                'labels': list_test_rezult[1]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'C количеством кластеров = лучшими значениями метрик на валидационной выборке',\n",
    "                'data': probs,\n",
    "                'data_type': 'полная',\n",
    "                'labels':  list_test_rezult[2]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'C лучшими значениями силуэта на тесте',\n",
    "                'data': probs,\n",
    "                'data_type': 'полная',\n",
    "                'labels': list_test_rezult[3]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'Выборка чистая с центройдами',\n",
    "                'data': probs_clear,\n",
    "                'data_type': 'чистая',\n",
    "                'labels': list_test_rezult[4]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'Выборка чистая количеством кластеров = сюжетов',\n",
    "                'data': probs_clear,\n",
    "                'data_type': 'чистая',\n",
    "                'labels': list_test_rezult[5]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'Выборка чистая с количеством кластеров с лучшими значениями метрик на валидационной выборке',\n",
    "                'data': probs_clear,\n",
    "                'data_type': 'чистая',\n",
    "                'labels': list_test_rezult[6]['labels']\n",
    "               },\n",
    "               {\n",
    "                'title':'Выборка чистая с лучшими значениями силуэта на тесте',\n",
    "                'data': probs_clear,\n",
    "                'data_type': 'чистая',\n",
    "                'labels': list_test_rezult[7]['labels']\n",
    "               }\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGyJoExIvBsj"
   },
   "outputs": [],
   "source": [
    "df_table = rezult_DF_test(test_rezult)\n",
    "df_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TF6f8wqD5zNX"
   },
   "source": [
    "#### Визуализируем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fE3Su858g3k"
   },
   "outputs": [],
   "source": [
    "# 'Выборка с установленными центройдами'\n",
    "printVizual(data_img_test, list_test_rezult[0]['labels'], suptitle = list_test_rezult[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73j6eO538UoY"
   },
   "outputs": [],
   "source": [
    "# 4. Выборка чистая с установленными центройдами\n",
    "printVizual(data_img_clear, list_test_rezult[4]['labels'], suptitle = list_test_rezult[4]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UivU4DhP8NNb"
   },
   "outputs": [],
   "source": [
    "# 6. Выборка чистая с количеством кластеров с лучшими значениями метрик на тесте\n",
    "printVizual(data_img_clear, list_test_rezult[6]['labels'], suptitle = list_test_rezult[6]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDVEQ6-dZyuv"
   },
   "outputs": [],
   "source": [
    "#7. Выборка чистая с лучшими значениями силуэта на тесте\n",
    "printVizual(data_img_clear, list_test_rezult[7]['labels'], suptitle = list_test_rezult[7]['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0R-bWGtv0B6"
   },
   "source": [
    "#### Сохранение результатов с лучшими параметрами класстаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wORyL2i5v023"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "      list_test_rezult[0]['title'],\n",
    "      list_test_rezult[2]['title'],\n",
    "      list_test_rezult[3]['title'],\n",
    "\n",
    "      list_test_rezult[4]['title'],\n",
    "      list_test_rezult[6]['title'],\n",
    "      list_test_rezult[7]['title'],\n",
    "      sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cByUtsRFv9yj"
   },
   "outputs": [],
   "source": [
    "save_claster_rezult(data_img_test, list_test_rezult[0]['labels'], param='KMeans_full_centr')\n",
    "save_claster_rezult(data_img_test, list_test_rezult[2]['labels'], param='KMeans_full_best')\n",
    "save_claster_rezult(data_img_test, list_test_rezult[3]['labels'], param='KMeans_full_siluet')\n",
    "\n",
    "save_claster_rezult(data_img_clear, list_test_rezult[4]['labels'], param='KMeans_clear_centr')\n",
    "save_claster_rezult(data_img_clear, list_test_rezult[6]['labels'], param='KMeans_clear_best')\n",
    "save_claster_rezult(data_img_clear, list_test_rezult[7]['labels'], param='KMeans_clear_siluet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tA2oRk1it1EX"
   },
   "outputs": [],
   "source": [
    "save_claster_rezult(data_img_test, list_test_rezult[0]['labels'], param='KMeans_full_centr')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
