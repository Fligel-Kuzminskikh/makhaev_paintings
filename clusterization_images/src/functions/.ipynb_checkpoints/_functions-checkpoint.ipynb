{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "973f47f4",
   "metadata": {},
   "source": [
    "## Многопоточность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607cca3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting to_pool.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile to_pool.py\n",
    "\n",
    "# для многоканальной обработки списка любой функцией\n",
    "\n",
    "# item_list - список элементов\n",
    "# method - функция-обработчик\n",
    "def to_pool(item_list, method):\n",
    "    with Pool(processes=os.cpu_count()) as pool:\n",
    "         rezult_list = []\n",
    "         for res in tqdm(pool.imap(method, (i for i in item_list)),\n",
    "                     total = len(item_list)):\n",
    "             rezult_list.append(res)\n",
    "    return rezult_list\n",
    "\n",
    "def to_tqdm(item_list, method):\n",
    "  rezult_list = []\n",
    "  for res in tqdm(map(method, (i for i in item_list)),\n",
    "                     total = len(item_list)):\n",
    "             rezult_list.append(res)\n",
    "  return rezult_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12b618f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting to_tqdm.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile to_tqdm.py\n",
    "\n",
    "# для передачи в счетчик выполнения обработки списка любой функцией\n",
    "\n",
    "# item_list - список элементов\n",
    "# method - функция-обработчик\n",
    "def to_tqdm(item_list, method):\n",
    "  rezult_list = []\n",
    "  for res in tqdm(map(method, (i for i in item_list)),\n",
    "                     total = len(item_list)):\n",
    "             rezult_list.append(res)\n",
    "  return rezult_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc501eef",
   "metadata": {},
   "source": [
    "## Изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1120c5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting show_img.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile show_img.py\n",
    "\n",
    "# вывод изображений\n",
    "\n",
    "# image_list - список словарей вида {'img':вектор изображения в формате PIL или CV2,'title':название}\n",
    "# name - булиан - выводить или нет заголовок изображения\n",
    "# col - количество колонок \n",
    "# cv2_img - булиан - передается картинка в формате CV2\n",
    "# suptitle - общий заголовок\n",
    "def show_img(image_list, name = True, col = 5, cv2_img = False, suptitle='', title_key = global_key):\n",
    "    row = len(image_list) // col + 1\n",
    "\n",
    "    plt.figure(figsize=(6.4, 2.4*row))\n",
    "    for i in range(0,len(image_list)):\n",
    "        plt.subplot(row, col, i + 1)\n",
    "        plt.suptitle(suptitle)\n",
    "        plt.axis('off')\n",
    "        if name:\n",
    "           title = str(image_list[i][title_key])\n",
    "        else:\n",
    "           title =  'N' + str(i+1) \n",
    "        plt.title(f\"{title}\") \n",
    "        if cv2_img:\n",
    "           plt.imshow(cv2.cvtColor(image_list[i]['img'], cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "           plt.imshow(image_list[i]['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ae76b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file2cv2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile file2cv2.py\n",
    "\n",
    "# конвертация в формат cv2\n",
    "# возвращает словарь вида {'img':вектор изображения в формате CV2,'title':название}\n",
    "\n",
    "# filename - полный путь к файлу\n",
    "def file2cv2(filename):     \n",
    "     return {'img':cv2.imread(filename), 'title':filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca34f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file2PIL.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile file2PIL.py\n",
    "\n",
    "# конвертация в формат cv2\n",
    "# возвращает словарь вида {'img':вектор изображения в формате PIL,'title':название}\n",
    "\n",
    "# filename - полный путь к файлу\n",
    "\n",
    "def file2PIL(filename):  \n",
    "     return {'img': Image.open(filename), 'title':filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18e8dd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_gray.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_gray.py\n",
    "\n",
    "# конвертация из BGR в gray\n",
    "\n",
    "# img - вектор изображенияв формат cv2\n",
    "\n",
    "def get_gray(img):\n",
    "   img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "   return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37952720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setPlotImg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setPlotImg.py\n",
    "# соединяет таблицу изображений и таблицу сюжетов по ключевому полю\n",
    "\n",
    "# df_plot - датафрейм с сюжетами, df_img - датафрейм с изображениями\n",
    "# loc_key = '' - название столбца по которому соединяются таблицы (если не указан - 'regNumber')\n",
    "def setPlotImg(df_plot, df_img, loc_key = ''):\n",
    "  key = loc_key if loc_key else global_key\n",
    "  key_plot_list = np.unique(df_plot[key].tolist())\n",
    "  df_temp = df_img.loc[df_img[key].isin(key_plot_list)]\n",
    " \n",
    "  return df_plot.merge(df_temp, on=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73af0c",
   "metadata": {},
   "source": [
    "### Коллаж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ca686bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting PIL_collage.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile PIL_collage.py\n",
    "\n",
    "from PIL import ImageFilter, ImageDraw, ImageFont\n",
    "\n",
    "# размеры картинок-миниатюр для вывода \n",
    "GLOBAL_thumb_size = (128, 128)\n",
    "# положение картинки на миниатюре, если она не вписывается в квадрат \n",
    "GLOBAL_resize_type = 'center'\n",
    "\n",
    "# количество картинок в ряду коллажа\n",
    "GLOBAL_сollage_cols = 5\n",
    "# фон картинок если не вписываются в превью, если не задан в качестве фона используем размытое изображени\n",
    "GLOBAL_bg_color = (232, 232, 232, 0)\n",
    "\n",
    "# путь к шрифту, используемому при добавлении надписи на изображение\n",
    "GLOBAL_font_family = \"./src/DinCyRg_.ttf\"\n",
    "# размер шрифта, по умолчанию при добавлении надписи на изображение\n",
    "GLOBAL_font_size = 30\n",
    "# цвет шрифта, по умолчанию при добавлении надписи на изображение\n",
    "GLOBAL_font_color = (9, 9, 9, 255)\n",
    "\n",
    "def get_text_dimensions(text_string, font):\n",
    "    # https://stackoverflow.com/a/46220683/9263761\n",
    "    ascent, descent = font.getmetrics()\n",
    "\n",
    "    text_width = font.getmask(text_string).getbbox()[2]\n",
    "    text_height = font.getmask(text_string).getbbox()[3] + descent\n",
    "\n",
    "    return (text_width, text_height, ascent, descent)\n",
    "\n",
    "def paste_text(\n",
    "       img_source, img_text, \n",
    "       inner_size = (0,0),\n",
    "       text_position = 'inner', \n",
    "       bg_color = GLOBAL_bg_color, \n",
    "       font_family = GLOBAL_font_family, \n",
    "       font_size=GLOBAL_font_size, \n",
    "       fill=GLOBAL_font_color, \n",
    "       align = 'left'):    \n",
    "    \n",
    "    font = ImageFont.truetype(font_family, font_size)\n",
    "    text_width, text_height, text_ascent, text_descent = get_text_dimensions(str(img_text), font)\n",
    "    \n",
    "    if (text_position == 'inner_top') | (text_position == 'inner_bottom'):\n",
    "       img = img_source.copy()      \n",
    "       \n",
    "       if text_position == 'inner_top':\n",
    "           y = (img_source.size[1] // 2) - (inner_size[1]//2) - text_height - text_descent\n",
    "       else:\n",
    "           y = (img_source.size[1] // 2) + (inner_size[1]//2) + text_height\n",
    "    \n",
    "    else:\n",
    "       # добавляем отсуп под текст          \n",
    "       adding_size = text_height  + text_descent    \n",
    "       img = Image.new('RGBA', (img_source.size[0], img_source.size[1] + adding_size), color = bg_color)    \n",
    "       cord_w = 0               \n",
    "       cord_h = adding_size if text_position == 'title' else 0           \n",
    "       img.paste(img_source, box=(cord_w, cord_h))\n",
    "       y = img_source.size[1] if text_position == 'bottom' else  0                 \n",
    "    \n",
    "    x = (img.size[0]-text_width)/2 if align== 'center' else 0    \n",
    "    position = (x, y)\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)    \n",
    "    #draw.text(position, str(img_text), fill=fill, font=font, align=align)    \n",
    "    draw.multiline_text(position, str(img_text), fill=fill, font=font, align=align)   \n",
    "    \n",
    "    return img\n",
    "\n",
    "# преведение картинок к заданному размеру для удобства коллажирования\n",
    "\n",
    "# img - картинка формата PIL\n",
    "# size = GLOBAL_thumb_size - размер к которому приводим картинки\n",
    "# bg_color = GLOBAL_bg_color - цвет фона блока если изображение не вписываются в превью, если не задан в качестве фона используем размытое изображени\n",
    "def resize_img(\n",
    "    img_source, \n",
    "    size = GLOBAL_thumb_size, \n",
    "    resize_type = GLOBAL_resize_type, \n",
    "    bg_color = GLOBAL_bg_color, \n",
    "    border = 0,\n",
    "    img_text_list = []\n",
    "    ):  \n",
    "    \n",
    "    img = img_source.copy()\n",
    "    thumbnail_size = (size[0] - 2*border, size[1] - 2*border)\n",
    "    \n",
    "    img.thumbnail(thumbnail_size)    \n",
    "    current_size = img.size\n",
    "    # если картинка не вписывается в квадрат, создаем фон из размытого изображения / или заданного цвета\n",
    "    if (current_size[0] < thumbnail_size[0]) | (current_size[1] < thumbnail_size[1]):\n",
    "       if bg_color:\n",
    "          new_img = Image.new('RGBA', size, color = bg_color)\n",
    "       else:\n",
    "          new_img = img.filter(filter=ImageFilter.GaussianBlur)              \n",
    "          new_img = new_img.resize(thumbnail_size)  \n",
    "       \n",
    "       if resize_type == 'center': #вставляем по центру квадрата\n",
    "          cord_w = (size[0]//2) - current_size[0]//2\n",
    "          cord_h = (size[1]//2) - current_size[1]//2  \n",
    "       else:\n",
    "          cord_w = (size[0]//2) - current_size[0]//2\n",
    "          cord_h = border\n",
    "       new_img.paste(img, box=(cord_w, cord_h))    \n",
    "    \n",
    "       # если есть текст - вставляем\n",
    "       if len(img_text_list) != 0:\n",
    "          for row in img_text_list:\n",
    "              img_text = row['text']\n",
    "              font_size  = row['font_size']\n",
    "              text_align  = row['text_align']\n",
    "              text_position = row['text_position']\n",
    "                \n",
    "              new_img = paste_text(new_img, img_text, inner_size = current_size, text_position = text_position, font_size=font_size, align = text_align)\n",
    "       return new_img\n",
    "\n",
    "    return img\n",
    "\n",
    "# находим суммарную/максимальную высоту всех картинок в листе\n",
    "def get_total_h(img_list, return_max = False):    \n",
    "    rezult_list = []\n",
    "    for img in img_list:\n",
    "        rezult_list.append(img.size[1])\n",
    "    if return_max:\n",
    "        rezult = max(rezult_list)\n",
    "    else:\n",
    "        rezult = sum(rezult_list)\n",
    "    return rezult\n",
    "\n",
    "# складываем картинки по высоте\n",
    "def set_full_img(img_list, total_w, bg_color = GLOBAL_bg_color):\n",
    "    total_h = get_total_h(img_list)\n",
    "    new_img = Image.new('RGBA', (total_w, total_h), color = bg_color)\n",
    "    y = 0\n",
    "    for img in img_list:\n",
    "        new_img.paste(img, (0, y))\n",
    "        y += img.size[1]\n",
    "        \n",
    "    return new_img\n",
    "\n",
    "# создание коллажа\n",
    "def create_collage(img_list, cols = GLOBAL_сollage_cols, size = GLOBAL_thumb_size):\n",
    "    thumb_width = size[0]\n",
    "    thumb_height = size[1]\n",
    "    # если список пустой - создаем пустую картинку заданной ширины\n",
    "    if len(img_list) == 0:\n",
    "       width = cols*thumb_width\n",
    "       height = thumb_height\n",
    "\n",
    "       new_img = Image.new('RGBA', (width, height))\n",
    "\n",
    "       return new_img\n",
    "\n",
    "    # определяем высоту и ширину коллажа    \n",
    "    # чтобы не подключать math ради одного округления вверх такая странная конструкция\n",
    "    rows = len(img_list) // cols if (len(img_list) // cols) == (len(img_list) / cols) else (len(img_list) // cols) + 1\n",
    "    \n",
    "    width = cols*thumb_width\n",
    "    height = rows*thumb_height\n",
    "    \n",
    "    new_img = Image.new('RGBA', (width, height))\n",
    "        \n",
    "    i, x, y = 0, 0, 0\n",
    "    for row in range(rows):        \n",
    "            if i == len(img_list):\n",
    "              break\n",
    "            for col in range(cols):\n",
    "                if i == len(img_list):\n",
    "                  break                    \n",
    "                new_img.paste(img_list[i], (x, y))\n",
    "                i += 1\n",
    "                x += thumb_width\n",
    "            y += thumb_height\n",
    "            x = 0\n",
    "\n",
    "    return new_img\n",
    "\n",
    "# конвертируем для коллажа cv2 в PIL\n",
    "def cv2PIL(opencv_image):\n",
    "    color_coverted = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2RGB)  \n",
    "    return Image.fromarray(color_coverted)\n",
    "\n",
    "# уменьшаем и выводим\n",
    "def makeCollage(list_img_to_collage, cols = GLOBAL_сollage_cols, cv2_img = False):\n",
    "    if cv2_img:\n",
    "       list_img_to_collage = to_pool(list_img_to_collage, eval('cv2PIL'))\n",
    "    images_small = to_pool(list_img_to_collage, eval('resize_img'))\n",
    "    images_collage = create_collage(images_small, cols = cols)\n",
    "    \n",
    "    return images_collage\n",
    "\n",
    "# уменьшаем и выводим с заданными параметрами\n",
    "def makeCollage_size(list_img_to_collage, cols = GLOBAL_сollage_cols, size = GLOBAL_thumb_size, bg_color = GLOBAL_bg_color, cv2_img = False):\n",
    "    if cv2_img:\n",
    "       list_img_to_collage = to_pool(list_img_to_collage, eval('cv2PIL'))\n",
    "    images_small = [resize_img(item, size = size, bg_color = bg_color) for item in list_img_to_collage]\n",
    "    images_collage = create_collage(images_small, cols = cols, size = size)\n",
    "    \n",
    "    return images_collage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b00e68f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print_collage_for_clasters.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_collage_for_clasters.py\n",
    "\n",
    "# словарь для расшифровки уровней опосредованностей\n",
    "GLOBAL_tree_dict = {\n",
    "    0:'Не имеет отношение к Махаеву',\n",
    "    1:'Авторский оригинал',\n",
    "    2:'По оригиналу Махаева',\n",
    "    3:'По гравюре с оригинала',\n",
    "    4:'Массовая продукция',\n",
    "    5:'Копия копии'\n",
    "}\n",
    "\n",
    "# печатаем только по сюжетам\n",
    "# df - датафрейм результатов для печати вида:\n",
    "#     колонка id, связывающая с пулом изображений (по умолчанию 'regNumber'),\n",
    "#     поле с номером сюжета (по умолчанию 'labels'), \n",
    "# img_df = data_img - дата изображений для визуализации\n",
    "# thumb_size=GLOBAL_thumb_size - размер миниатюр каждого изображения в итоговом коллаже\n",
    "# cols = GLOBAL_сollage_cols - количество колонок в коллаже\n",
    "# col_key = 'labels' - id поля с номером сюжета\n",
    "def print_labels(df, \n",
    "                 img_df = data_img, \n",
    "                 thumb_size=GLOBAL_thumb_size,                            \n",
    "                 cols = GLOBAL_сollage_cols,\n",
    "                 col_key = 'labels'\n",
    "                 ):\n",
    "    labels_list = np.unique(df[col_key])\n",
    "\n",
    "    full_img_w = thumb_size[0]*cols\n",
    "\n",
    "    collage_list = []\n",
    "\n",
    "    for i in labels_list:\n",
    "        plot_title = 'Сюжет №' + str(i)\n",
    "        collage_list_plot = []\n",
    "        \n",
    "        # берем все id сюжета = i\n",
    "        key_list = df[(df[col_key] == i)][global_key].tolist()\n",
    "        if len(key_list) == 0:\n",
    "           continue        \n",
    "\n",
    "        img_list_temp = img_df[img_df[global_key].isin(key_list)].copy().to_dict(orient='records')        \n",
    "        \n",
    "        for item in img_list_temp:\n",
    "            text_list = [{'text': item[global_key], 'font_size': 12,'text_align': 'center','text_position':'inner_bottom'}]\n",
    "            if printTrueConnect:\n",
    "                    connect_key = df[df[global_key] == item[global_key]][col_connect].tolist()[0]                    \n",
    "                    true_connect = GLOBAL_tree_dict[connect_key]\n",
    "                    \n",
    "                    text_list.append({'text': true_connect,'font_size': 12,'text_align': 'center','text_position':'inner_top'})\n",
    "            img = resize_img(item['img'], size = thumb_size, border = 24, img_text_list = text_list)\n",
    "            collage_list_plot.append(img)  \n",
    "            \n",
    "        max_img_h = max(thumb_size[1], get_total_h(collage_list_plot, return_max = True))        \n",
    "        plot_img =  create_collage(collage_list_plot, cols = cols, size = (thumb_size[0], max_img_h))\n",
    "        plot_img = paste_text(plot_img, plot_title, text_position = 'title')\n",
    "        collage_list.append(plot_img)\n",
    "\n",
    "    full_img = set_full_img(collage_list, full_img_w) \n",
    "    return full_img\n",
    "\n",
    "# печатаем по классам + уровням опосредованности\n",
    "# df - датафрейм результатов для печати вида:\n",
    "#      колонка id, связывающая с пулом изображений (по умолчанию 'regNumber'),\n",
    "#      поле с номером сюжета (по умолчанию 'labels'),\n",
    "#      колонка с номером предсказанного уровня опосредовательности (по умолчанию 'class_predict')\n",
    "#      при необходимости печати реального уровня колонка с номером реального уровня опосредовательности (по умолчанию 'connectedness')\n",
    "# img_df = data_img - дата изображений для визуализации\n",
    "# thumb_size=GLOBAL_thumb_size - размер миниатюр каждого изображения в итоговом коллаже\n",
    "# cols = GLOBAL_сollage_cols - количество колонок в коллаже\n",
    "# col_key = 'class_predict'- id поля с номером уровня\n",
    "# col_plot = 'labels' - id поля с номером сюжета\n",
    "# printTrueConnect = False, - дополнять изображение реальным уровнем опосредовательности\n",
    "# col_connect = 'connectedness' - id поля с номером реального уровня опосредовательности \n",
    "def print_labels_classif(df, \n",
    "                          img_df = data_img, \n",
    "                          thumb_size=GLOBAL_thumb_size,                            \n",
    "                          cols = GLOBAL_сollage_cols,\n",
    "                          col_key = 'class_predict',\n",
    "                          col_plot = 'labels',\n",
    "                          printTrueConnect = False,\n",
    "                          col_connect = 'connectedness'\n",
    "                         ):\n",
    "    labels_list = np.unique(df[col_plot])\n",
    "    level_list = np.unique(df[col_key])\n",
    "\n",
    "    full_img_w = thumb_size[0]*cols\n",
    "\n",
    "    collage_list = []\n",
    "\n",
    "    for i in labels_list:\n",
    "        plot_title = 'Сюжет №' + str(i)\n",
    "        collage_list_plot = []\n",
    "\n",
    "        for j in level_list:        \n",
    "            level_title = GLOBAL_tree_dict[j]\n",
    "\n",
    "            # берем все id сюжета = i и уровня опосредовательности = j\n",
    "            key_list = df[(df[col_plot] == i) & (df[col_key] == j)][global_key].tolist()\n",
    "            if len(key_list) == 0:\n",
    "                continue        \n",
    "\n",
    "            img_list_temp = img_df[img_df[global_key].isin(key_list)].copy().to_dict(orient='records')        \n",
    "            collage_list_level = []\n",
    "            for item in img_list_temp:  \n",
    "                text_list = [{'text': item[global_key], 'font_size': 12,'text_align': 'center','text_position':'inner_bottom'}]\n",
    "                if printTrueConnect:\n",
    "                    connect_key = df[df[global_key] == item[global_key]][col_connect].tolist()[0]                    \n",
    "                    true_connect = GLOBAL_tree_dict[connect_key]\n",
    "                    \n",
    "                    text_list.append({'text': true_connect,'font_size': 12,'text_align': 'center','text_position':'inner_top'})\n",
    "                img = resize_img(item['img'], size = thumb_size, border = 24, img_text_list = text_list)                  \n",
    "                collage_list_level.append(img)  \n",
    "\n",
    "            max_img_h = max(thumb_size[1], get_total_h(collage_list_level, return_max = True))        \n",
    "            level_img = create_collage(collage_list_level, cols = cols, size = (thumb_size[0], max_img_h))                \n",
    "            level_img = paste_text(level_img, level_title, font_size=24, text_position = 'title')\n",
    "\n",
    "            collage_list_plot.append(level_img)    \n",
    "\n",
    "        plot_img = set_full_img(collage_list_plot, full_img_w)\n",
    "        plot_img = paste_text(plot_img, plot_title, text_position = 'title')\n",
    "        collage_list.append(plot_img)\n",
    "\n",
    "    full_img = set_full_img(collage_list, full_img_w) \n",
    "    return full_img\n",
    "\n",
    "\n",
    "# создает произвольный коллаж из переданных параметров без разделения по уровням\n",
    "\n",
    "# df - дата фрейм связанный с img_df ключом\n",
    "# img_df - дата фрейм с колонками 'img' - типа PIC/CV2, 'title' - имя картинки = ссылка на картинку в выгрузке \n",
    "# sampel_size = 300, size = GLOBAL_thumb_size, cols = GLOBAL_сollage_cols, cv2_img = False - параметры печати\n",
    "\n",
    "def printVizualCollag_univers(df, img_df = data_img, sampel_size = 300, size = GLOBAL_thumb_size, cols = GLOBAL_сollage_cols, cv2_img = False):\n",
    "    list_temp = df[global_key].tolist()\n",
    "    rezult_list = img_df[img_df[global_key].isin(list_temp)]['img'].tolist()  \n",
    "   \n",
    "    if len(rezult_list) > sampel_size:\n",
    "       rezult_list = sample(rezult_list, sampel_size)\n",
    "    \n",
    "    return makeCollage_size(rezult_list, size = size, cols = cols, cv2_img = cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebfc90b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing printVizualCollag.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile printVizualCollag.py\n",
    "\n",
    "# создает коллаж, согласно кластаризации\n",
    "\n",
    "# img_df - дата фрейм с колонками 'img' - типа PIC, 'title' - имя картинки = ссылка на картинку в выгрузке \n",
    "# labels - список лейблов\n",
    "# key - ключ кластера\n",
    "# sampel_size = 30, size = GLOBAL_thumb_size, cols = GLOBAL_сollage_cols, cv2_img = False - параметры печати\n",
    "def printVizualCollag(img_df, labels, key=0, sampel_size = 30, size = GLOBAL_thumb_size, cols = GLOBAL_сollage_cols, cv2_img = False):\n",
    "    df_temp = pd.DataFrame({'img': img_df['img'], 'title': img_df['title'], 'labels':labels})\n",
    "    rezult_list = df_temp[df_temp['labels'] == key]['img'].tolist()\n",
    "    if len(rezult_list) > sampel_size:\n",
    "       rezult_list = sample(rezult_list, sampel_size)\n",
    "    \n",
    "    return makeCollage_size(rezult_list, size = size, cols = cols, cv2_img = cv2_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd09e91c",
   "metadata": {},
   "source": [
    "## Тензоры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c089ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing image_features_get.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile image_features_get.py\n",
    "\n",
    "# получает тензор изображения с помощью clip-model\n",
    "# возвращает обект типа tensor()\n",
    "\n",
    "# image - вектор изображения формата PIL\n",
    "def image_features_get(image):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    image_features = model.get_image_features(**inputs)\n",
    "\n",
    "    return image_features.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b721a8",
   "metadata": {},
   "source": [
    "## SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af7cf3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_sorted_kp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_sorted_kp.py\n",
    "\n",
    "# сортировка ключевых точек\n",
    "\n",
    "#kp - массив ключевых точек, полученных из SIFT\n",
    "\n",
    "def get_sorted_kp(kp):\n",
    "    return sorted(kp, key = lambda x: x.response, reverse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fa5b62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_sift_kp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_sift_kp.py\n",
    "\n",
    "# получение ключевых точек sift\n",
    "# возвращает массив ключевых точек и ч/б изображение в формате вектора CV2\n",
    "\n",
    "#img - вектор изображения формата CV2\n",
    "def get_sift_kp(img, sift = cv2.SIFT_create()):    \n",
    "    gray = get_gray(img) \n",
    "    kp_all = sift.detect(gray,None)\n",
    "    kp = get_sorted_kp(kp_all)\n",
    "\n",
    "    return kp, gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92c45be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing set_sift_dict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile set_sift_dict.py\n",
    "\n",
    "# получение ключевых точек\n",
    "# возвращает словарь вида \n",
    "# {'img':вектор изображения формата CV2, 'gray':вектор ч/б изображения формата CV2, 'title':название изображения, 'kp':массив ключевых точек}\n",
    "\n",
    "#img_info - словарь вида {'img':вектор изображения формата CV2, 'title':название изображения}\n",
    "def set_sift_dict(img_info):\n",
    "    name_list = ['img','gray','title','kp']\n",
    "    img, title = img_info['img'], img_info['title']\n",
    "    kp, gray = get_sift_kp(img)\n",
    "    img_dict = dict(zip(name_list,[img, gray, title, kp]))\n",
    "    \n",
    "    return img_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d4a22fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_sift_des.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_sift_des.py\n",
    "\n",
    "# получение массива deskriptors ключевых точек\n",
    "# возвращает массив deskriptors\n",
    "\n",
    "#img_info - словарь вида \n",
    "# {'gray':вектор ч/б изображения формата CV2, 'kp':массив ключевых точек}\n",
    "def get_sift_des(img_info, sift = cv2.SIFT_create()):  \n",
    "  gray, kp = img_info['gray'], img_info['kp']\n",
    "  return sift.compute(gray,kp)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea941585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing set_sift_des.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile set_sift_des.py\n",
    "\n",
    "# создает словарь deskriptors, переданных изображений\n",
    "# возвращает список deskriptors переданных изображений\n",
    "\n",
    "# sift_dict - словарь вида \n",
    "# {'img':вектор изображения формата CV2, 'gray':вектор ч/б изображения формата CV2, 'title':название изображения, 'kp':массив ключевых точек}\n",
    "def set_sift_des(sift_dict):  \n",
    "  gray = pd.DataFrame(sift_dict)['gray'].tolist()\n",
    "  # находим минимальное количество ключевых точек для всех изображений\n",
    "  len_kp_list = [len(item['kp']) for item in sift_dict]\n",
    "  lemit = min(set(len_kp_list)) \n",
    "  # Оставляем лучшие точки\n",
    "  kp_list = [item['kp'][:lemit] for item in sift_dict]  \n",
    "  kp_dict = pd.DataFrame({'gray': gray, 'kp': kp_list}).to_dict(orient='records')\n",
    "  \n",
    "  des_list = to_tqdm(kp_dict, eval('get_sift_des'))\n",
    "\n",
    "  return des_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7313ff",
   "metadata": {},
   "source": [
    "## Чтение/запись файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8522d542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_file_list.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_file_list.py\n",
    "\n",
    "# считать список файлов из всех поддерикторий\n",
    "# возвращает список имен файлов и уникальные расширения файлов\n",
    "\n",
    "# path - путь к директории type - str\n",
    "# name_list - список названий файлов по которому фильтруем type - list\n",
    "def get_file_list(path, name_list = []):\n",
    "    rezult = []\n",
    "    variant = set()\n",
    "    for root, dirs, files in os.walk(path, topdown = False):        \n",
    "        for name in files:\n",
    "            if len(name_list) > 0:\n",
    "               if not(filter_fille_name(name, name_list)):\n",
    "                  continue\n",
    "            \n",
    "            rezult.append(os.path.join(root, name))\n",
    "            # если нет расширений у файлов добавляем None, иначе - название расширения\n",
    "            file_extension = name.split('.')[1] if len(name.split('.')) > 1 else None\n",
    "            variant.add(file_extension) \n",
    "    return rezult, variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52dd15b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting filter_fille_name.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile filter_fille_name.py\n",
    "\n",
    "# на вход передается путь к имени файла и список id объектов. id соответствует первой части имени файла\n",
    "# по маске id_*.jpg\n",
    "# возвращает булево значение есть id в списке или нет\n",
    "\n",
    "# fille_path - полный путь к файлу\n",
    "# id_list - список id\n",
    "def filter_fille_name(fille_path, id_list):   \n",
    "    fille_name = fille_path.split('/')[-1]\n",
    "    return fille_name.split('.')[0].split('_')[0] in id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78cb4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting getImgId.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getImgId.py\n",
    "\n",
    "# возвращает id объекта из пути к файлу картинки и преффикс 1 или 2\n",
    "\n",
    "# fille_path - путь к файлу\n",
    "def setImgId(fille_path):  \n",
    "  fille_name = fille_path.split('/')[-1]\n",
    "  return fille_name.split('.')[0].split('_')[0], fille_name.split('.')[0].split('_')[1]  \n",
    "\n",
    "# возвращает id объекта из пути к файлу картинки\n",
    "# fille_path - путь к файлу\n",
    "def getImgId(fille_path):    \n",
    "  return int(setImgId(fille_path)[0])\n",
    "\n",
    "# возвращает преффикс 1 или 2 объекта из пути к файлу картинки\n",
    "\n",
    "# fille_path - путь к файлу\n",
    "def filterImgPreff(fille_path, pref_list = [1, '1']):  \n",
    "    fille_pref = setImgId(fille_path)[1]\n",
    "    return fille_pref in pref_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a69591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing setTrueLabel.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setTrueLabel.py\n",
    "\n",
    "# возвращает метку кластера для переданного изображения\n",
    "\n",
    "# line - словарь вида {'img': изображение формата PIA/CV2, 'title':путь к файлу, 'regNumber':id по которому матчатся таблицы}\n",
    "# loc_key = '' - название столбца по которому соединяются таблицы (если не указан - 'regNumber')\n",
    "def setTrueLabel(line, loc_key = ''):\n",
    "  key = loc_key if loc_key else global_key\n",
    "  img_id = int(line[key])\n",
    "  return valid_table_df.loc[valid_table_df[key] == img_id]['label_true'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab476bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting downloadFromDriverCSV.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile downloadFromDriverCSV.py\n",
    "\n",
    "# скачать с гугл-диска таблицу в формате csv\n",
    "# возвращает таблицу\n",
    "\n",
    "# url - ссылка доступа, полученная с гугл-диска\n",
    "def downloadFromDriverCSV(url, sep=','):\n",
    "   file_id=url.split('/')[-2]\n",
    "   dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "   df = pd.read_csv(dwn_url, encoding = 'utf8', sep = sep)\n",
    "\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2e58fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting save2csv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save2csv.py\n",
    "\n",
    "# сохраняем в файл результаты\n",
    "def save2csv(df, param='data'):\n",
    "    file_name = './out/' + param + '_' + str(randint(100, 2000)) +'.csv'\n",
    "    df.to_csv(file_name, index= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df3850d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting csv2DF.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile csv2DF.py\n",
    "\n",
    "# загрузка файлов по словарю\n",
    "# name - имя\n",
    "# link_dir - словарь\n",
    "# sep = \",\" - разделитель\n",
    "def csv2DF(name, link_dir = url_dict, sep = \",\"):\n",
    "    url = link_dir[name]\n",
    "    df = pd.read_csv(url, encoding = 'utf8', sep = sep )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7eff67",
   "metadata": {},
   "source": [
    "## Кластаризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbc25773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print_claster_count.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_claster_count.py\n",
    "\n",
    "# выводит на печать словарь вида {кластер:количество элементов в нем}\n",
    "\n",
    "# labels - список лейблов\n",
    "def print_claster_count(labels):\n",
    "    print(dict(Counter(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e1d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print_claster.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_claster.py\n",
    "\n",
    "# выводит на экран изображения принадлежащие к конкретному кластеру\n",
    "\n",
    "# df - датафрейм с столбцами 'img' (вектор изображения PIL или CV2), 'title' (заголовок), 'labels' (присвоенный класс)\n",
    "# label - наименование класса,\n",
    "# sampel_size = 30 - максимальный размер выборки изображений,\n",
    "# suptitle = '' - заголовок для печати блока изображений,\n",
    "# cv2_img = False - булеан использовать формат cv2 или нет, \n",
    "# name = False -  булеан печатать имя картинки или нет, \n",
    "def print_claster(df, label, sampel_size = 30, suptitle = '', cv2_img = False, name = False):\n",
    "  rezult_df = df[df['labels'] == label].to_dict(orient='records')\n",
    "  if len(rezult_df) > sampel_size:\n",
    "     show_img(sample(rezult_df, sampel_size), name = name, suptitle = suptitle, cv2_img = cv2_img)\n",
    "  else:\n",
    "     show_img(rezult_df, name = name, suptitle = suptitle, cv2_img = cv2_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acadeb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print_img_in_classters.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_img_in_classters.py\n",
    "\n",
    "# выводит на печать изображения по всем кластерам\n",
    "# df - датафрейм с столбцами 'img' (вектор изображения PIL или CV2), 'title' (заголовок), 'labels' (присвоенный класс)\n",
    "# sampel_size = 30 - максимальный размер выборки изображений,\n",
    "# cv2_img = False - булеан использовать формат cv2 или нет, \n",
    "# name = False -  булеан печатать имя картинки или нет, \n",
    "def print_img_in_classters(df, cv2_img = False, sampel_size = 30, suptitle = '', name = False):    \n",
    "    for k in np.unique(df['labels']):\n",
    "        df_temp = df[df['labels'] == k]\n",
    "        suptitle = '-'.join([str(k), str(len(df_temp))])\n",
    "        print_claster(df, k, suptitle = suptitle, sampel_size = sampel_size, cv2_img = cv2_img , name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0f305e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting printVizual.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile printVizual.py\n",
    "\n",
    "# выводит на печать картинки из переданного списка, согласно кластаризации\n",
    "# или печатает только один класс, если есть ключ кластера\n",
    "\n",
    "# img_df - дата фрейм с колонками 'img' - типа PIC/CV, 'title' - имя картинки = ссылка на картинку в выгрузке \n",
    "# labels - список лейблов\n",
    "# key - ключ кластера\n",
    "# printOneClaster = False, - печатаем все или только выбранный кластер\n",
    "# sampel_size = 30, suptitle = '', cv2_img = False, name = False - параметры печати\n",
    "def printVizual(img_df, labels, key=False, printOneClaster = False, sampel_size = 30, suptitle = '', cv2_img = False, name = False):\n",
    "    df_temp = pd.DataFrame({'img': img_df['img'], 'title': img_df['title'], 'labels':labels})\n",
    "    if printOneClaster:\n",
    "       print_claster(df_temp, key, sampel_size = sampel_size, suptitle = suptitle, cv2_img = cv2_img, name =name)\n",
    "    else:\n",
    "       print_img_in_classters(df_temp, sampel_size = sampel_size, suptitle = suptitle, cv2_img = cv2_img, name =name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c89c3",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bc0c098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_dbscan_label_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_dbscan_label_test.py\n",
    "\n",
    "# применяет DBSCAN с переданными параметрами\n",
    "# возвращает список полученных лейблов\n",
    "\n",
    "# X - список фичей,\n",
    "# eps=0.1, min_samples=4, metric='cosine' - параметры DBSCAN,\n",
    "# (подробней https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)\n",
    "# scale  -   булево значение стандартизировать или нет перед применение DBSCAN\n",
    "# norm  -   булево значение нормализовать или нет перед применение DBSCAN\n",
    "def get_dbscan_label_test(X, eps=0.1, min_samples=4, metric='cosine', scale = True, norm = True):\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples, metric=metric)\n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    db.fit(X)\n",
    "    return db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be0c03e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_dbscan_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_dbscan_test.py\n",
    "\n",
    "#  результаты кластерезации методом DBSCAN с различными параметрами\n",
    "# возвращает лист словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера, 'n_clusters_':количество кластеров, 'n_noise_':количество шума}\n",
    "# отсортированный по возрастанию шума\n",
    "\n",
    "# X - список фичей,\n",
    "# param_list - список словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера}\n",
    "# min_claster_count = 2 - минимальное количество кластеров, которое должно получится в выборке\n",
    "# getScore = False - печатать оценку кластеризации\n",
    "# Y='' - список классов для валидации\n",
    "# score_funcs_list = '' - список кортежей формата (название_функции, функция) (по умолчанию global_score_funcs)\n",
    "\n",
    "def get_dbscan_test(X, param_list, min_claster_count = 2, getScore = False, Y='', score_funcs_list = ''):\n",
    "    rezult = []\n",
    "    for row in param_list:\n",
    "       min_samples = row['min_samples']\n",
    "       eps = row['eps']\n",
    "       labels =  get_dbscan_label_test(X, eps=eps, min_samples=min_samples)       \n",
    "       n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "       n_noise_ = list(labels).count(-1)\n",
    "       if getScore:\n",
    "          score_funcs_list = score_funcs_list if score_funcs_list else global_score_funcs\n",
    "          rezult.append({'eps':eps, 'min_samples':min_samples, 'n_clusters_':n_clusters_, 'n_noise_':n_noise_, 'score_list':getMetricsRezult(labels, Y, score_funcs_list)})\n",
    "       else:\n",
    "          rezult.append({'eps':eps, 'min_samples':min_samples, 'n_clusters_':n_clusters_, 'n_noise_':n_noise_})\n",
    "\n",
    "    rezult = list(filter(lambda item: item['n_clusters_'] > min_claster_count, rezult))\n",
    "    rezult = sorted(rezult, key=lambda item: item['n_noise_'])\n",
    "    \n",
    "    return rezult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f473525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print_dbscan_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_dbscan_test.py\n",
    "\n",
    "# печатает результаты кластерезации методом DBSCAN с различными параметрами\n",
    "\n",
    "# X - список фичей,\n",
    "# param_list - список словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера}\n",
    "# getScore = False - печатать оценку кластеризации\n",
    "# Y='' - список классов для валидации\n",
    "# score_funcs_list = '' - список кортежей формата (название_функции, функция) (по умолчанию global_score_funcs)\n",
    "def print_dbscan_test(X, param_list, getScore = False, Y='', score_funcs_list = ''):\n",
    "    for row in param_list:\n",
    "       min_samples = row['min_samples']\n",
    "       eps = row['eps']\n",
    "       labels =  get_dbscan_label_test(X, eps=eps, min_samples=min_samples)\n",
    "       \n",
    "       n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "       n_noise_ = list(labels).count(-1)\n",
    "       print(f'eps={eps}, min_samples={min_samples}')\n",
    "       print(f'Количество кластеров : {n_clusters_}. Количество шума: {n_noise_} ')\n",
    "       print(print_claster_count(labels))\n",
    "       if getScore:\n",
    "          score_funcs_list = score_funcs_list if score_funcs_list else global_score_funcs\n",
    "          score_list = getMetricsRezult(labels, Y, score_funcs_list)\n",
    "          print(*score_list, sep='\\n')\n",
    "       print('+'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb1e79bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting set_dbscan_param.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile set_dbscan_param.py\n",
    "\n",
    "# создает список параметров и проводит для них тестирование DBSCAN\n",
    "# в зависимости от флага выводит на печать результаты \n",
    "# возвращает лист словарей вида {'eps':значение eps, 'min_samples':минимальный размер кластера, 'n_clusters_':количество кластеров, 'n_noise_':количество шума}\n",
    "# отсортированный по возрастанию шума\n",
    "\n",
    "# X - список фичей,\n",
    "# eps_list - список eps для которых будет формироваться лист параметров\n",
    "# samples_list = [3, 4] - список min_samples для которых будет формироваться лист параметров\n",
    "# print=False - булево значение печатать результаты тестов \n",
    "# getScore = False - печатать оценку кластеризации\n",
    "# Y='' - список классов для валидации\n",
    "# score_funcs_list = '' - список кортежей формата (название_функции, функция) (по умолчанию global_score_funcs)\n",
    "def set_dbscan_param(X, eps_list, samples_list = [3, 4], print=False, getScore = False, Y=''):\n",
    "    min_samples_list = []\n",
    "    for i in samples_list:\n",
    "        min_samples_list = min_samples_list + len(eps_list) * [i]\n",
    "    param_list = pd.DataFrame(list(zip(eps_list*len(samples_list), min_samples_list)),columns =['eps', 'min_samples']).to_dict(orient='records')\n",
    "    if print:\n",
    "       print_dbscan_test(X, param_list, getScore = getScore, Y=Y)\n",
    "    else:\n",
    "       return get_dbscan_test(X, param_list, getScore = getScore, Y=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fec8c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing print_сlustering_param.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_сlustering_param.py\n",
    "\n",
    "# выводит на печать результаты кластаризации DBSCAN\n",
    "\n",
    "# labels - список полученных лейблов\n",
    "def print_сlustering_param(labels):\n",
    "  n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "  n_noise_ = list(labels).count(-1)\n",
    "  print(f'Количество кластеров : {n_clusters_}. Количество шума: {n_noise_} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf92a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting print_kneeLocatore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_kneeLocatore.py\n",
    "\n",
    "# метод для нахождения оптимального eps для DBSCAN,\n",
    "# используется для дальнейшего построения графика \"колена\"\n",
    "# возвращает средние дистанции между точками набора, полученные методом NearestNeighbors\n",
    "\n",
    "# X - список фичей,\n",
    "# num = 21 -  параметр earestNeighbors, количество соседей = MinPts, которое будет использоваться в DBSCAN,\n",
    "# print_plt = False - булево значение печать график или нет\n",
    "# scale  -   булево значение стандартизировать или нет перед применение NearestNeighbors\n",
    "# norm  -   булево значение нормализовать или нет перед применение NearestNeighbors\n",
    "def get_neighbors(X, num = 21, print_plt = False, scale = True, norm = True):\n",
    "  neigh = NearestNeighbors(n_neighbors=num)\n",
    "  if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "  if norm:\n",
    "       X = normalize(X)\n",
    "  nbrs = neigh.fit(X)\n",
    "  distances, indices = nbrs.kneighbors(X)\n",
    "  distances = np.sort(distances[:,num-1], axis=0)\n",
    "  if print_plt:\n",
    "     fig = plt.figure(figsize = (18, 9))\n",
    "     plt.plot(distances)\n",
    "     plt.xlabel('Points')\n",
    "     plt.ylabel('Distance')\n",
    "\n",
    "  return distances\n",
    "\n",
    "\n",
    "# возвращает значенеи \"колена\"\n",
    "\n",
    "# dist - дистанции между соседями, полученные методом NearestNeighbors\n",
    "# print_plt = False - булево значение печать график или нет\n",
    "def get_kneeLocatore(dist, print_plt = False):\n",
    "    x, y = np.arange(len(dist)), dist\n",
    "    kneedle = KneeLocator(x, y, S=1.0, curve=\"convex\", direction=\"increasing\")\n",
    "    if print_plt:\n",
    "       kneedle.plot_knee_normalized()\n",
    "    \n",
    "    knee_point = kneedle.knee\n",
    "    elbow_point = kneedle.elbow\n",
    "    return knee_point, elbow_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1367a6",
   "metadata": {},
   "source": [
    "### РСА\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76af17d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing get_PCA.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_PCA.py\n",
    "\n",
    "# Сокращение размерности Метод главных компонент\n",
    "# Возвращает трансформированный список фечей и объект pca\n",
    "\n",
    "# X - список фичей,\n",
    "# components = 2 - размерность до которой сокращаем\n",
    "def get_PCA(X, components = 2):\n",
    "    pca = PCA(components)  \n",
    "    projected = pca.fit_transform(X)\n",
    "    \n",
    "    return projected, pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40690700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing print_PCA.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile print_PCA.py\n",
    "\n",
    "# выводит на печать количество дисперсии, объясненной каждой компонентой\n",
    "\n",
    "# pca - объект pca\n",
    "def print_PCA(pca):\n",
    "    for i, component in enumerate(pca.components_):\n",
    "        print(\"{} component: {}% объясненной дисперсии\".format(i + 1, \n",
    "          round(100 * pca.explained_variance_ratio_[i], 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0299bb7",
   "metadata": {},
   "source": [
    "### OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d90d98da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_OPTICS_label_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_OPTICS_label_test.py\n",
    "\n",
    "# применяет OPTICS с переданными параметрами\n",
    "# возвращает список полученных лейблов\n",
    "\n",
    "# X - список фичей,\n",
    "# min_samples=5, xi=0.05, min_cluster_size=0.05, cluster_method='xi',  metric='co - параметры OPTICS,\n",
    "# (подробней https://scikit-learn.org/stable/modules/generated/sklearn.cluster.OPTICS.html#sklearn.cluster.OPTICS)\n",
    "# scale  -   булево значение стандартизировать или нет перед применение OPTICS\n",
    "# norm  -   булево значение нормализовать или нет перед применение OPTICS\n",
    "def get_OPTICS_label_test(X, \n",
    "                          min_samples=5, xi=0.05, min_cluster_size=0.05, cluster_method='xi',  metric='cosine',                           \n",
    "                          scale = True, norm = True):\n",
    "\n",
    "    optics_model = OPTICS(min_samples=min_samples, metric=metric, cluster_method=cluster_method, xi=xi, min_cluster_size=min_cluster_size)\n",
    "    \n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    optics_model.fit(X)\n",
    "        \n",
    "    labels = optics_model.labels_[optics_model.ordering_]\n",
    "    \n",
    "    return labels\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94210b3",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7711ce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_KMeans_labels.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_KMeans_labels.py\n",
    "\n",
    "# применяет KMeans с переданными параметрами\n",
    "# возвращает список полученных лейблов\n",
    "\n",
    "# X - список фичей,\n",
    "# k - количество кластеров,\n",
    "# n_init= 'auto', random_state=1 - параметры KMeans\n",
    "# scale  -   булево значение стандартизировать или нет перед применение KMeans\n",
    "# norm  -   булево значение нормализовать или нет перед применение KMeans\n",
    "# use_centroids = False - использовать переданный массив центройдов\n",
    "# centroids = '' - центройды\n",
    "def get_KMeans_labels(X, k, scale = True, norm = True, use_centroids = False, centroids = '', n_init= 'auto', random_state=1):\n",
    "    if use_centroids:\n",
    "       # если передаем центройды\n",
    "       kmeans = KMeans(n_clusters=max(2, len(centroids)), init=centroids, n_init=1, random_state=random_state)\n",
    "    else:\n",
    "       kmeans = KMeans(n_clusters=max(k,2), n_init=n_init, random_state=random_state)\n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    kmeans.fit(X)\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e97429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting get_klasters_set.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile get_klasters_set.py\n",
    "\n",
    "# нахождение оптимального количества кластеров для KMeans,\n",
    "# методом силуэта\n",
    "# возвращает средние значение силуэта для выбранного количества кластеров\n",
    "\n",
    "# X - список фичей,\n",
    "# num = 10 -  параметр KMeans, количество примененеий метода для рассчета среднего значения силуэта,\n",
    "# scale  -   булево значение стандартизировать или нет перед применение KMeans\n",
    "# norm  -   булево значение нормализовать или нет перед применение KMeans\n",
    "\n",
    "def get_KMeans_silhouette_score(X, k, num = 10, scale = True, norm = True):\n",
    "    kmeans = KMeans(n_clusters=max(k,2), n_init= 'auto', random_state=num)\n",
    "    if scale:\n",
    "       scaler = StandardScaler()\n",
    "       X = scaler.fit_transform(X)\n",
    "    if norm:\n",
    "       X = normalize(X)\n",
    "    kmeans.fit(X)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "\n",
    "    return silhouette_avg\n",
    "\n",
    "# рассчитывает значение силуэта для различных k в заданном диапазоне\n",
    "# возвращаем словарь вида {количество кластеров:значение силуэта}\n",
    "\n",
    "# X - список фичей,\n",
    "# start = 10, end = 110, step_list = [10, 5, 1] - диапазон в которых проверяме значения k и шаг с которым выполняем проверку\n",
    "# set_len = 3 - размер возвращаемого словаря\n",
    "# scale  -   булево значение стандартизировать или нет перед применение KMeans\n",
    "# norm  -   булево значение нормализовать или нет перед применение KMeans\n",
    "def get_klasters_set(X, start = 10, end = 110, step_list = [10, 5, 1], set_len = 3, scale = True, norm = True):\n",
    "    current_start = start\n",
    "    current_end = end\n",
    "    for step in step_list:\n",
    "        # считаем для каждого k значение силуэта        \n",
    "        k_dict = {max(k, 2): get_KMeans_silhouette_score(X, k, scale = scale, norm = norm) for k in range(current_start, current_end, step)}\n",
    "        # сортируем результаты по значениям силуэта\n",
    "        k_dict = dict(sorted(k_dict.items(), key=lambda item: item[1], reverse = True))\n",
    "\n",
    "        # print(k_dict)\n",
    "        # берем два k с самыми высокими значениями и сортируем их по возрастанию k\n",
    "        # таким образом получаем новые значения current_start и current_end\n",
    "        param = sorted(list(k_dict.items())[0:2])\n",
    "        current_start, current_end = param[0][0], param[1][0] + 1\n",
    "\n",
    "    # берем первые значения из списка (по умолчанию - 3)\n",
    "    rezult = list(k_dict.items())[0:set_len]\n",
    "    # получем список кластеров\n",
    "    #return [i[0] for i in rezult]\n",
    "    return rezult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6777a8",
   "metadata": {},
   "source": [
    "## Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c3bab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing getMetricsRezult.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile getMetricsRezult.py\n",
    "\n",
    "# возвращает результаты проверки кластеризации различными метриками\n",
    "\n",
    "# x- предсказанные метки, y - истинные метки\n",
    "# score_funcs_list - список кортежей формата (название_функции, функция)\n",
    "\n",
    "def getMetricsRezult(x, y, score_funcs_list):\n",
    "    rezult_list = []\n",
    "    for func in score_funcs_list:\n",
    "        score_func = func[1]\n",
    "        score_name = func[0]\n",
    "        rezult = score_func(y, x)\n",
    "        rezult_list.append({'score_name': score_name, 'score':rezult})\n",
    "    return rezult_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6b601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
